---
title: "Exercise solutions"
format: html
---

## Lab 1

## Lab 2

**2.1** Use the functions described in yesterdays lab to get a quick overview of the dataset and give a brief summary of it.

```{r}
glimpse(d_bl)
head(d_bl)
ncol(d_bl)
nrow(d_bl)
```

**2.5** Calculate spread measures for the LSAS-SR scale, what do they tell you and which ones do you think are most useful to describe the spread of the values. Motivate your answer briefly!

```{r}
sd(d_bl$lsas_screen)
var(d_bl$lsas_screen)
range(d_bl$lsas_screen)
IQR(d_bl$lsas_screen)
hist(d_bl$lsas_screen)
```

**Overcourse:**

**2.6** Calculate the *population variance and standard deviation*. How do these differ from the ones given by the functions `sd()` and `var()`.

```{r}
# variance
x_bar <- mean(d_bl$lsas_screen)
n <- nrow(d_bl)
residuals <- d_bl$lsas_screen - x_bar
squared_residuals <- residuals^2
sigma_squared_residuals <- sum(squared_residuals)
s_2 <- sigma_squared_residuals/n
s_2 # population variance
var(d_bl$lsas_screen) # sample variance

#standard deviation
sd <- sqrt(s_2)
sd
sd(d_bl$lsas_screen)
```

**2.7** Use only the first ten participants and compare the population and the sample variance and standard deviation of LSAS-SR. What do you find, and how do the results compare to those from exercise 2.6.

```{r}
d_bl_10 <- d_bl[1:10,]
# variance
x_bar <- mean(d_bl_10$lsas_screen)
n <- nrow(d_bl_10)
residuals <- d_bl_10$lsas_screen - x_bar
squared_residuals <- residuals^2
sigma_squared_residuals <- sum(squared_residuals)
s_2 <- sigma_squared_residuals/n
s_2 # population variance
var(d_bl_10$lsas_screen) # sample variance

#standard deviation
sd <- sqrt(s_2)
sd
sd(d_bl_10$lsas_screen)
```

**2.9** Visualize the joint distribution of GAD-7 and PHQ-9 as numeric variables and describe what you see

```{r}
plot(d_bl$gad_screen, d_bl$phq9_screen)
abline(lm(d_bl$gad_screen ~d_bl$phq9_screen))
```

**2.10** Visualize the distribution of of LSAS scores by income level and describe what you see

```{r}
boxplot(d_bl$lsas_screen~d_bl$income)
```

**2.11** Create a variable for high vs. low DERS scores and investigate the joint distribution of this variable and phq_cat (that we created in an earlier example)

```{r}
d_bl$ders_screen_cat <- ifelse(d_bl$ders_screen>median(d_bl$ders_screen),
                               "High DERS",
                               "Low DERS") 

plot(table(d_bl$ders_screen_cat, d_bl$phq_cat), main = "Depression and Emotion regulation")
```

**2.12** Create a table using the tableone package to show descriptives statistics stratified by high vs low depression levels. Briefly interpret what you see.

```{r}
library(tableone)
vars <- c(
  "lsas_screen",
  "gad_screen",
  "phq9_screen",
  "bbq_screen",
  "scs_screen",
  "dmrsodf_screen",
  "ders_screen",
  "pid_5_screen",
  "gender",
  "education",
  "income"
)

CreateContTable(vars= vars, data= d_bl, strata = "phq_cat")
```

## Lab 3

**3.1** Estimate the standard error of LSAS_Screen in the STePS study using the formula above, and describe in words what the number means

```{r}
s_2 <- var(d_bl$lsas_screen)
n <- nrow(d_bl)
se <- sqrt(s_2/n)

# or using the standard deviation

se <- sd(d_bl$lsas_screen)/sqrt(n)
```

**3.2** Calculate the standard error for the proportion of men in the STePS study, and describe the meaning of this number in words

```{r}
p_hat <- mean(d_bl$gender=="Man")
n <- nrow(d_bl)          
se <- sqrt(p_hat*(1-p_hat)/n)
```

**3.3** Describe what would happen to these standard errors if the sample size had been 1000 participants and explain why?

**3.4** Calculate the two-sided p-value for the null hypothesis that the mean PHQ-9 value in the underlying population is 9, and describe in words what this number mean.

```{r}
x_bar <- mean(d_bl$phq9_screen)
se <- sd(d_bl$phq9_screen) / sqrt(nrow(d_bl))
t_value <- (x_bar - 9) / se
(1 - pt(t_value, df = 180))*2

#or

t.test(d_bl$phq9_screen,
       mu=9,
       alternative = "two.sided")
```

**3.5** Calculate the p-value for getting our observed proportion of men, $\hat{p}$, if the the true population proportion, $p$, is 40% or more using a z-test.

HINT: use the standard error of the proportion: $$ \mathrm{SE}(p) = \sqrt{\frac{p(1 - p)}{n}} $$

and combine with the formula for the z-scores

$$ z= \frac{p - \hat{p}}{SE} $$

```{r}
p_hat <- mean(d_bl$gender=="Man")
p <- 0.4          
n <- nrow(d_bl)          
se <- sqrt(p*(1-p)/n)
z_value <- (p_hat - p) / se
1- pnorm(abs(z_value))

# or 
prop.test(x= sum(d_bl$gender=="Man"), 
          n= length(d_bl$gender), 
          p=0.4,
          alternative="less",
          correct = FALSE)
```

**3.6** Modify the simulation code for the sampling distribution above to determine what would happen to the p-value if the sample size was 10, 100 or 1000

P-value with a sample size of 10

```{r}
n_samples <- 1e4 # the number of samples
smp_size <- 10 # the size of our samples
means <- rep(NA, n_samples) # an empty vector to contain our mean values

for (i in 1:n_samples) {
  x <- rnorm(smp_size, mean = 82, sd = sd(d_bl$lsas_screen))
  means[i] <- mean(x)
}

mean(means >= mean(d_bl$lsas_screen)) # proportion of simulated means that are larger than our observed mean

```

P-value with a sample size of 100

```{r}
n_samples <- 1e4 # the number of samples
smp_size <- 100 # the size of our samples
means <- rep(NA, n_samples) # an empty vector to contain our mean values

for (i in 1:n_samples) {
  x <- rnorm(smp_size, mean = 82, sd = sd(d_bl$lsas_screen))
  means[i] <- mean(x)
}

mean(means >= mean(d_bl$lsas_screen)) # proportion of simulated means that are larger than our observed mean
```

P-value with a sample size of 10000

```{r}
n_samples <- 1e4 # the number of samples
smp_size <- 1000 # the size of our samples
means <- rep(NA, n_samples) # an empty vector to contain our mean values

for (i in 1:n_samples) {
  x <- rnorm(smp_size, mean = 82, sd = sd(d_bl$lsas_screen))
  means[i] <- mean(x)
}

mean(means >= mean(d_bl$lsas_screen)) # proportion of simulated means that are larger than our observed mean
```

**3.7.** Explain why the confidence intervals calculated using z-scores are narrower that the ones using t-scores.

**3.8** Calculate the 95% confidence interval for PHQ-9, and describe in words what these numbers mean.

```{r}
x_bar <- mean(d_bl$phq9_screen)
se <- sd(d_bl$phq9_screen) / sqrt(nrow(d_bl))
z <- 1.96

#upper confidence limit
ucl <- x_bar + z*se
#lower confidence limit
lcl <- x_bar - z*se

print(c(lcl, ucl))

#or
t.test(d_bl$phq9_screen,
       mu=9,
       alternative = "two.sided")
```

**3.9** Calculate the 95% Wald confidence interval for the proportion of men in the dataset using the formula above and interpret its meaning

```{r}
p_hat <- mean(d_bl$gender=="Man")
n = nrow(d_bl)
se <- sqrt(p_hat*(1-p_hat)/n)
z= 1.96
#upper coinfidence limit
p_hat + z*se
#lower confidence limit
p_hat - z*se

```

**3.10** Compare this to what you would obtain using the function `prop.test()` in R.

```{r}
prop.test(table(d_bl$gender))
```

**3.11** Reason about the the meaning and interpretation of the confidence intervals you have calculated in the context of how the actual STePs study was performed. The study can be found at: <https://www.nature.com/articles/s44184-024-00063-0>
