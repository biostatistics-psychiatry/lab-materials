---
title: "Lab 1: Import and clean data"
---

For this first lab session, we will:

- Introduce the datasets we will be using throughout the course
- Import data into R
- Perform basic cleaning of the data

# Introduction to the datasets

::: callout-note
These datasets have the common .csv file format, which is very popular. If you need to import other file formats, such as .xlsx (Excel) or .sav (SPSS), you can use the `readxl` and `haven` packages, respectively.
:::

## STePS-study

This is a dataset from the STePS study, which is a RCT comparing guided and unguided internet-delivered psychodynamic therapy for social anxiety disorder. The study [is published online](https://www.nature.com/articles/s44184-024-00063-0).

## Anh√∂rigSpel-study

# Load packages

In this lab, we will be using the *tidyverse* package, which is a collection of useful packages for data manipulation and visualization. We will also use the *here* package, which helps us manage file paths in a simple way.

```{r}
#| label: load-packages
#| message: false

library(tidyverse)
library(here)
library(janitor)
```

::: callout-warning
If you are using `R` for the first time, you have to run the following code in the **console** to install the packages (one time only!). You can then load them using the code above.

```{r}
#| eval: false

install.packages("tidyverse")
install.packages("here")
```
:::

# Importing data into R

Let's start with the *STePS* dataset. We use the `read_csv()` function, along with the `here()` function, to import the data. Within the `here()` function, we first specify the folder, then the filename. This is helpful for keeping the file paths clean, and makes it easier to share your code with others since the file paths are relative to the project folder.

We also check the number of rows and columns in the dataset after importing it.

```{r}
#| label: import-steps
#| message: false

df_rawdata <- read_csv2(here("data", "steps_raw.csv"))

row_check <- nrow(df_rawdata) # 181
col_check <- ncol(df_rawdata) # 37
```

## Check data structure

After importing the data, we can check the structure of the dataset using the `glimpse()` function. This function provides a quick overview of the dataset, including the number of rows and columns, as well as the data types of each column. Does it look as expected?

Your object `df_rawdata` should contain `r row_check` rows and `r col_check` columns. We can see that the first column is named *ID*, which is the unique identifier for each participant. The second column is named *Group*, which indicates the group assignment: unguided treatment, guided treatment, or waitlist. The rest seem to be various questionnaires and scales.

```{r}
#| label: glimpse-data
#| message: false

glimpse(df_rawdata)
```

Other options for checking the basic structure of the data include `head()`, `names()`, `ncol()`, and `nrow()`.

- `head(df_rawdata)` shows the first few rows of the dataset.
- `names(df_rawdata)` shows the names of the columns.
- `ncol(df_rawdata)` shows the number of columns in the dataset.
- `nrow(df_rawdata)` shows the number of rows in the dataset.

Try them out!

# Data cleaning

From the output above, we can see some potential issues with the raw data:

- Some column names contain spaces and other problematic characters (such as `-`).
- There are missing values in several columns.
- The measurement points are not consistent.
- The data types of some columns are not as expected (e.g., character instead of numeric).

Let's get started with cleaning the data. Before we proceed, we will create a copy of the raw data and leave `df_rawdata` unchanged. This is a good practice to avoid losing the original data and to keep track of the changes we make.

::: callout-important
Make a habit of keeping the raw data you import from data collection platforms (e.g., BASS, REDCap) unchanged. This way, your life will be easier when you need to do new exports or updates. You can always go back to the original data if needed.
:::

```{r}
#| label: copy-data
#| message: false

df_data <- df_rawdata
```

## Clean column names

We will use the `clean_names()` function from the *janitor* package to clean the column names. This function replaces spaces and other problematic characters with underscores, and converts all names to lowercase. This makes it easier to work with the data later on.

What's wrong with these column names? And what is the difference after `clean_names()`?

```{r}
#| label: bad-column-names
#| message: false

names(df_data)
```

```{r}
#| label: clean-column-names
#| message: false

df_data <- df_data |> 
  clean_names()

names(df_data)
```

We have sorted some of the problems, but we still have inconsistent names for time-points (*screening* and *screen*), and some questionnaires seems to have gotten inconsistent names as well (*ders_16*, *ders16*, and *ders*).

```{r}
#| label: fix-column-inconsistencies
#| message: false

df_data <- df_data |> 
  rename_with(~ .x |> 
    str_replace_all("screening", "screen") |> 
    str_replace_all("ders_16|ders16", "ders") |> 
    str_replace_all("phq_9", "phq9")
  )

names(df_data)
```

::: {.callout-tip}
## This is rarely a linear process

This type of data cleaning is often a result of going back and forth between running code and checking the results. Sometimes you will come all the way to the analyses before finding that DERS-16 is missing a time-point! This is why it's helpful to design your code in a way that allows you to easily go back and forth.
:::

## Ensure missing values are coded as NA

If we are lucky, all the missing values are already coded as `NA` and R will recognize them as missing. More often, however, is that the missing values are coded as `""`, `-99`, or other values. This can cause problems later, so we need to ensure that all missing values are coded as `NA`.

Sometimes, weird labels for missing values is also the reason why some columns are not recognized as numeric.

Let's check the data structure again. It looks like some columns that should be numeric are instead `<chr>`, which means they are character strings.

```{r}
#| label: check-missing-values
#| message: false

glimpse(df_data)

```

Let's fix this by replacing the problematic values with `NA`. We will use the `mutate()` and `across()` functions from the *dplyr* package to apply the `na_if()` function to all character columns. This will replace any occurrence of "missing" with `NA`.

```{r}
#| label: fix-missing-values
#| message: false

df_data <- df_data |> 
  mutate(across(where(is.character), ~na_if(., "missing")))

```

## Fix column types

The NA values are now correctly coded, but we still have some columns that are not numeric despite only including numbers. We can use the `mutate()` function again to convert the columns to the correct data type. In this step, we also ensure that the `id` and `group` columns are factors.

```{r}
#| label: fix-column-types
#| message: false

# which columns should be numeric?
num_cols <- c("lsas", "gad", "phq9", "bbq", "scs", "dmrsodf", "ders", "pid_5")

df_data <- df_data |> 
  mutate(
    across(starts_with(num_cols), as.numeric),
    id = factor(id),
    group = factor(group)
  )

```

Let's check that it worked.

```{r}
#| label: check-column-types
#| message: false

glimpse(df_data)
```

# Save the cleaned data

Now that we have cleaned the data, we can save it as a new CSV file. We will use the `write_csv()` function from the *readr* package to do this. The cleaned data will be saved in the `data` folder with the name `steps_clean.csv`.

```{r}
#| label: save-cleaned-data
#| message: false

write_csv(df_data, here("data", "steps_clean.csv"))
```
