---
title: "Import and clean data"
---

For this first lab session, we will:

- Introduce the datasets we will be using throughout the course
- Import data into R
- Perform basic cleaning of the data

# Introduction to the dataset

::: callout-note
This datasets have the common .csv file format, which is very popular. If you need to import other file formats, such as .xlsx (Excel) or .sav (SPSS), you can use the `readxl` and `haven` packages, respectively.
:::

## STePS-study

This is a dataset from the STePS study, which is a RCT comparing guided and unguided internet-delivered psychodynamic therapy for social anxiety disorder. The study [is published online](https://www.nature.com/articles/s44184-024-00063-0).

In true open science fashion, the data is openly available online from the [Open Science Framework](https://osf.io/cxmte/files/621b1b8c-392f-4c40-97f4-bdf60e133a4c?view_only=). 

# Load packages

We will be using the *tidyverse* package quite a lot in this course. *Tidyverse* is a collection of useful packages for data manipulation and visualization, such as `dplyr` and `ggplot2`. We will also use the *here* package, which helps us manage file paths in a simple way. Finally, the *janitor* package has a great function for cleaning column names.

```{r}
#| label: load-packages
#| message: false

library(tidyverse)
library(here)
library(janitor)
```

If you are using `R` for the first time, you have to run the following code in the **console** to install the packages (one time only!). You can then load them using the `library()` function.

```{r}
#| eval: false

if (!require(tidyverse)) install.packages("tidyverse")
if (!require(here)) install.packages("here")
```

::: {.callout-tip}
## R packages

There is a rich ecosystem of *packages* for R, which add functionality to the base R language. You can find specialised packages for many different tasks. It's important to keep in mind, however, that these are developed open source, and it is good practice to always read the documentation so that you understand how to use the package correctly.

:::

# Importing data into R

Let's start working with the *STePS* dataset. We use the `read_csv()` function, along with the `here()` function, to import the data. Within the `here()` function, we first specify the folder, then the filename. This is helpful for keeping the file paths clean, and makes it easier to share your code with others since the file paths are relative to the project folder.

We also check the number of rows and columns in the dataset after importing it.

```{r}
#| label: import-steps
#| message: false

df_rawdata <- read_csv2(here("data", "steps_raw.csv"))

row_check <- nrow(df_rawdata) # 181
col_check <- ncol(df_rawdata) # 37
```

::: {#exr-import-steps .callout-caution collapse="true"}
## Import the STePS dataset

Import the STePS dataset using the `read_csv()` function. Use the `here()` function to specify the file path. Check the number of rows and columns in the dataset after importing it.

:::

## Check data structure

After importing the data, we can check the structure of the dataset using the `glimpse()` function. This function provides a quick overview of the dataset, including the number of rows and columns, as well as the data types of each column. Does it look as expected?

Your object `df_rawdata` should contain `r row_check` rows and `r col_check` columns. We can see that the first column is named *ID*, which is the unique identifier for each participant. The second column is named *Group*, which indicates the group assignment: unguided treatment, guided treatment, or waitlist. The rest seem to be various questionnaires and scales.

```{r}
#| label: glimpse-data
#| message: false

glimpse(df_rawdata)
```

Other options for checking the basic structure of the data include `head()`, `names()`, `ncol()`, and `nrow()`.

- `head(df_rawdata)` shows the first few rows of the dataset.
- `names(df_rawdata)` shows the names of the columns.
- `ncol(df_rawdata)` shows the number of columns in the dataset.
- `nrow(df_rawdata)` shows the number of rows in the dataset.

::: {#exr-glimpse-data .callout-caution collapse="true"}
## Check the structure of STePS

use the `glimpse()` function to check the structure of the STePS data. What do you notice about the data? Are there any potential issues with the data structure?

Also try calling `view()` to open the data in a spreadsheet-like view.
:::

# Data cleaning

From the output above, we can see some potential issues with the raw data:

- Some column names contain spaces and other problematic characters (such as `-`).
- There are missing values in several columns.
- The measurement points are not consistent.
- The data types of some columns are not as expected (e.g., character instead of numeric).

Let's get started with cleaning the data. Before we proceed, we will create a copy of the raw data and leave `df_rawdata` unchanged. This is a good practice to avoid losing the original data and to keep track of the changes we make.

::: callout-important
Make a habit of keeping the raw data you import from data collection platforms (e.g., BASS, REDCap) unchanged. This way, your life will be easier when you need to do new exports or updates. You can always go back to the original data if needed.
:::

```{r}
#| label: copy-data
#| message: false

df_data <- df_rawdata
```

## Clean column names

We will use the `clean_names()` function from the *janitor* package to clean the column names. This function replaces spaces and other problematic characters with underscores, and converts all names to lowercase. This makes it easier to work with the data later on.

What's wrong with these column names? And what is the difference after `clean_names()`?

::: {#exr-clean-names .callout-caution collapse="true"}
##  Clean column names, part 1

Use the `clean_names()` function to clean the column names in `df_data`. Check the names before and after cleaning. What changes do you notice? Are there any column names that are still problematic?
:::

```{r}
#| label: bad-column-names
#| message: false

names(df_data)
```

```{r}
#| label: clean-column-names
#| message: false

df_data <- df_data |>
  clean_names()
```

We have sorted some of the problems, but we still have inconsistent names for time-points (*screening* and *screen*), and some questionnaires seems to have gotten inconsistent names as well (*ders_16*, *ders16*, and *ders*).

```{r}
#| label: fix-column-inconsistencies
#| message: false

df_data <- df_data |>
  rename_with(~ .x |>
    str_replace_all("screening", "screen") |>
    str_replace_all("ders_16|ders16", "ders") |>
    str_replace_all("phq_9", "phq9"))
```

::: {.callout-tip}
## This is rarely a linear process

This type of data cleaning is often a result of going back and forth between running code and checking the results. Sometimes you will come all the way to the analyses before finding that DERS-16 is missing a time-point! This is why it's helpful to design your project in a way that allows you to easily go back and forth between steps.
:::

::: {#exr-clean-names-2 .callout-caution collapse="true"}
##  Clean column names, part 2

Use the `rename_with()` function to fix the column names of PHQ-9 in `df_data`. Check the names before and after cleaning. What changes do you notice? Are there any column names that are still problematic?
:::

## Ensure missing values are coded as NA

If we are lucky, all the missing values are already coded as `NA` and R will recognize them as missing. More often, however, is that the missing values are coded as `""`, `-99`, or other values. This can cause problems later, so we need to ensure that all missing values are coded as `NA`.

Sometimes, weird labels for missing values is also the reason why some columns are not recognized as numeric.

Let's check the data structure again. It looks like some columns that should be numeric are instead `<chr>`, which means they are character strings.

```{r}
#| label: check-missing-values
#| message: false

glimpse(df_data)
```

Let's fix this by replacing the problematic values with `NA`. We will use the `mutate()` and `across()` functions from the *dplyr* package to apply the `na_if()` function to all character columns. This will replace any occurrence of "missing" with `NA`.

```{r}
#| label: fix-missing-values
#| message: false

df_data <- df_data |>
  mutate(across(where(is.character), ~ na_if(., "missing")))

```

::: {#exr-fix-missing-values .callout-caution collapse="true"}
##  Fix missing values

Check which columns have weird values for missing values. You can use the `glimpse()` function or view the data in the viewer. You can also use the `unique()` function to check which values are present in a column.

Then, use the `mutate()` and `across()` functions to replace these values with `NA`. Make sure to replace all occurrences of "missing" in the character columns.
:::

## Fix column types

The NA values are now correctly coded, but we still have some columns that are not numeric despite only including numbers. We can use the `mutate()` function again to convert the columns to the correct data type. In this step, we also ensure that the `id` and `group` columns are factors.

```{r}
#| label: fix-column-types
#| message: false

# which columns should be numeric?
num_cols <- c("lsas", "gad", "phq9", "bbq", "scs", "dmrsodf", "ders", "pid_5")

df_data <- df_data |>
  mutate(
    across(starts_with(num_cols), as.numeric),
    id = factor(id),
    group = factor(group)
  )

```

::: {#exr-fix-column-types .callout-caution collapse="true"}
## Fix column types

Let's imagine we have many columns that should be factors. How can you use the same procedure as above to convert all columns from a `fct_cols` vector to factors?
:::

# Create a treatment indicator variable

Our *group* variable is coded as 0, 1, and 2. This is not very informative, and we run the risk of misinterpreting the results if we don't have clear labels for the three groups. Let's create a new variable `trt` with better labels.

```{r}
#| label: trt-factor

df_data <- df_data |>
  mutate(
    trt = factor(
      group,
      levels = c(0, 1, 2),
      labels = c("waitlist", "self-guided", "therapist-guided")
    )
  )

```

# Save the cleaned data

Now that we have cleaned the data, we can save it as a new CSV file. We will use the `write_csv()` function from the *readr* package to do this. The cleaned data will be saved in the `data` folder with the name `steps_clean.csv`.

```{r}
#| label: save-cleaned-data
#| message: false

write_csv(df_data, here("data", "steps_clean.csv"))
```

::: {.callout-tip}
## Saving data

When working with data in your research projects, it's a good idea to save your data in formats that can be reused later. In this course we are using an open dataset, but for your own projects you may want to save your data on KI server or another secure location.

Try to keep your file names readable and understandable for both machines and humans.

- Avoid spaces or special characters in file names
- Use underscores `_` or hyphens `-` to separate words
- Use lowercase letters
- Use date stamps when relevant (e.g., `bass_export_2024_01_15.csv`)
- Use descriptive names (e.g., `steps_baseline.csv`)
- Be consistent in naming

:::
