{
  "hash": "540523cefd514565817b7a5b118bd86f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Sampling from a population\"\n---\n\nSo far, we have restricted ourselves to describing the sample that we have. Often, however, we are not only interested about our sample, but want to make inferences about the **population** from which our sample came.\n\n# Load packages and data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\nlibrary(tidyverse)\nd_bl <- read_rds(here(\"data\", \"steps_baseline.rds\"))\n```\n:::\n\n\n# Central Limit Theorem (CLT):\n\nNo matter what the population distribution looks like, if you take many random samples and calculate their means, those samples means will form a **normal distribution** as the sample size grows large.\n\n- Sample means become normally distributed.\n- Happens even if the original population is **not normal**.\n- Works better as **sample size increases** (n â‰¥ 30 is a common rule).\n\nHere is a simulation to visualize what the relation between the distribution of a variable in the population and the sampling distribution of the means from that same population.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sampling_files/figure-html/clt-normal-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sampling_files/figure-html/clt-uniform-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sampling_files/figure-html/clt-bimodal-1.png){width=672}\n:::\n:::\n\n\n# Law of Large Numbers (LLN):\n\nAs you collect more and more observations, the **sample mean** (or proportion) will get closer and closer to the **true population mean**.\n\n- More data = more accuracy.\n- Guarantees that with enough data, **random variation** averages out.\n\nImagine that we had the patience to flip a coin 1000 times. For each toss, we calculated the number of heads we've gotten so far and divided by the total tosses, to get the proportion that landed heads. Even if we expect the coin to be fair, we wouldn't expect it to be 50-50 heads and tails in the beginning. In fact, at the first toss that would be impossible, As we continued, however, we would see the proportion of heads gradually stabilize around 0.5.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](sampling_files/figure-html/lln-coin-1.png){width=672}\n:::\n:::\n\n\nTogether the central limit theorem and the law of large numbers tells us that when sampling from a population 1) the sampling distribution approaches a normal distribution as the number of samples increases, AND 2) the value of the sample mean $\\bar{x}$, the estimate, will approach the true population mean $\\mu$ as the sample size increase.\n\n# Sampling in research\n\nThis is all fine and well, but you may find yourself wondering \"How does this help my PhD?\". You won't be able to sample repeatedly from the population, if you are lucky you'll have ONE sample to work with. But there is an upside! You can use you sample values to estimate *the standard deviation of the sampling distribution*, also known as the **standard error (SE).**\n\n## Standard error of a mean\n\nThe formula for the standard error of a mean, if we knew the population variance $\\sigma^2$, is:\n\n$$\nSE = {\\sqrt{\\sigma^2 / n}}\n$$\n\nHowever, we rarely know the population standard deviation. Luckily we can use the sample variance $s^2$ to estimate it:\n\n$$\nSE = {\\sqrt{s^2 / n}}\n$$\n\n## Standard error of a proportion\n\nFor a proportion, the standard error for the population is calculated by the formula:\n\n$$\n\\mathrm{SE}(p) = \\sqrt{\\frac{p(1 - p)}{n}}\n$$\n\n::: {#exr-se-lsas .callout-caution collapse=\"true\"}\n## Standard Error of LSAS_Screen\n\nEstimate the standard error of LSAS_Screen in the STePS study using the formula above, and describe in words what the number means.\n:::\n\n::: {#exr-se-proportion .callout-caution collapse=\"true\"}\n## Standard Error of Proportion\n\nCalculate the standard error for the proportion of men in the STePS study, and describe the meaning of this number in words.\n:::\n\n::: {#exr-sample-size-effect .callout-caution collapse=\"true\"}\n## Effect of Sample Size on Standard Error\n\nDescribe what would happen to these standard errors if the sample size had been 1000 participants and explain why?\n:::\n",
    "supporting": [
      "sampling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}