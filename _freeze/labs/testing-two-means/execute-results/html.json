{
  "hash": "acd5f8da460b375a385a25b97428eae1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Testing two means and contingency tables\"\n---\n\nIn this lab we focus on testing differences between groups. Previously we have calculated p-values and confidence intervals for one-sample means and proportions. In psychiatric research, we are more often interested in comparing means between groups. For instance, the post-treatment symptom levels between the treatment group and the control group.\n\nIn the STepS study, a primary comparison was the severity of social anxiety symptoms post-treatment between the self-guided and the therapist-guided treatment groups. As a first check, we can load the data and calculate get some descriptive statistics for the post-treatment LSAS-scores across the treatment groups.\n\n# Load packages and data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\ndf_data <- read_csv(here(\"data\", \"steps_clean.csv\"))\n```\n:::\n\n\n# Testing the mean difference of two independent groups\n\nAnd check the mean post-treatment LSAS-score across the groups\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_data |>\n  group_by(trt) |>\n  summarise(\n    n      = n(),\n    mean   = mean(lsas_post, na.rm = TRUE),\n    sd     = sd(lsas_post, na.rm = TRUE)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  trt                  n  mean    sd\n  <chr>            <int> <dbl> <dbl>\n1 self-guided         61  64.9  21.1\n2 therapist-guided    60  57.4  23.2\n3 waitlist            60  78.4  25.4\n```\n\n\n:::\n:::\n\n\nWe see that the therapist-guided groups has the lowest treatment scores post-treatment. We can also do a simple check of differences in the mean values across the groups of interest.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(df_data$lsas_post[df_data$trt == \"self-guided\"], na.rm = TRUE) -\n  mean(df_data$lsas_post[df_data$trt == \"therapist-guided\"], na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7.560429\n```\n\n\n:::\n:::\n\n\nSo the mean values of LSAS-scores is 7.6 point higher in the treatment group receiving self-guided treatment compared to the group receiving therapist-guided treatment. However, we still do not know how likely this difference is to have occurred by chance. For this we need a statistical test!\n\nTo test the difference between two means, we can use the Student's independent groups t-test:\n\n$$\nt = \\frac{\\bar{X}_1 - \\bar{X}_2}{SE_{\\text{pooled}}}\n$$\n\nWhere $\\bar{X_1}$ and $\\bar{X_2}$ are the means of the first and second group, and where the pooled standard error is:\n\n$$\nSE_{\\text{pooled}} = \\sqrt{s_p^2 \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}\n$$\n\nand the pooled variance is:\n\n$$\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n$$\n\nRather than comparing the mean value against some value of interest, as in the one-sample t-test, here we compare the means of two groups against each other. Usually this is done under the null hypothesis:\n\n$$\nH_{0}: \\mu_{\\text{therapist-guided}} = \\mu_{\\text{self-guided}}\n$$\n\nand the alternative hypothesis:\n\n$$\nH_{A}: \\mu_{\\text{therapist-guided}} \\neq \\mu_{\\text{self-guided}}\n$$\n\nThis may all seem complicated, but the **t-value simply represents the mean difference, expressed in standard errors units**. In other words, the number of standard errors between the means. Let's use the formulas above to calculate a t-value.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define the components of the t-test formula\nx_bar_tg <- mean(df_data$lsas_post[df_data$trt == \"therapist-guided\"], na.rm = T)\nx_bar_sg <- mean(df_data$lsas_post[df_data$trt == \"self-guided\"], na.rm = T)\ns_2_tg <- var(df_data$lsas_post[df_data$trt == \"therapist-guided\"], na.rm = T)\ns_2_sg <- var(df_data$lsas_post[df_data$trt == \"self-guided\"], na.rm = T)\nn_tg <- sum(!is.na(df_data$lsas_post[df_data$trt == \"therapist-guided\"])) # here we only count the number of persons that provided data\nn_sg <- sum(!is.na(df_data$lsas_post[df_data$trt == \"self-guided\"])) # here we only count the number of persons that provided data\nsp2 <- ((n_tg - 1) * s_2_tg + (n_sg - 1) * s_2_sg) / (n_tg + n_sg - 2) # pooled variance\nSE_pooled <- sqrt(sp2 * (1 / n_tg + 1 / n_sg)) # pooled standard error\n\n# and put the together\nt_value <- (x_bar_sg - x_bar_tg) / SE_pooled\nt_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.799271\n```\n\n\n:::\n:::\n\n\nAnd use the t-distribution with $n_1 + n_2 - 2$ degrees of freedom to get the p-value for this specific t-value\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- n_tg + n_sg - 2\np_value <- 2 * (1 - pt(abs(t_value), df)) # multiplied by two to get the two-tailed p-value\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.07474269\n```\n\n\n:::\n:::\n\n\nOr use the `t.test()` function, and filter to remove the waitlist group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(lsas_post ~ trt,\n  data = df_data[df_data$trt != \"waitlist\", ],\n  var.equal = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  lsas_post by trt\nt = 1.7993, df = 109, p-value = 0.07474\nalternative hypothesis: true difference in means between group self-guided and group therapist-guided is not equal to 0\n95 percent confidence interval:\n -0.7676792 15.8885369\nsample estimates:\n     mean in group self-guided mean in group therapist-guided \n                      64.91228                       57.35185 \n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Assumptions of an Independent Groups *t*-test\n\n1.  **Independence of observations**\n    -   The two groups must be independent (no participant in both groups, no repeated measures).\n2.  **Scale of measurement**\n    -   The dependent variable should be continuous (interval or ratio).\n    -   The independent variable should be categorical with two groups.\n3.  **Normality**\n    -   The dependent variable in each group should be approximately normally distributed.\n    -   More critical for small samples; larger samples benefit from the Central Limit Theorem.\n4.  **Homogeneity of variance**\n    -   Both groups should have equal variances.\n    -   If violated, use Welch’s *t*-test instead (set the argument var.equal = FALSE in the `t.test()` function)\n5.  **Random sampling**\n    -   Ideally, groups are randomly sampled or randomly assigned in an experiment.\n:::\n\nWe can also get the **confidence interval for this mean difference.** As always, the confidence interval is calculated by taking the estimate of interest, in this case the mean difference $\\pm$ our desired number of standard errors. For a confidence interval with large samples, the sampling distribution approaches the z-distribution (normal distribution with $\\mu = 0$ and $\\sigma = 1$). We can then use the z-values covering the middle 95% of the z-distribution, which are $\\pm 1.96$. To check that the $z_\\alpha/2$ for an alpha of 0.05 is indeed $\\pm 1.96$ we could use the the function `qnorm()` that gives the quantile function of the normal distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(1 - 0.05 / 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.959964\n```\n\n\n:::\n:::\n\n\nThe formula for the confidence interval of the mean difference using z-values is:\n\n$$\n(\\bar{X}_1 - \\bar{X}_2) \\;\\pm\\; z_{\\alpha/2} \\cdot SE_{z}\n$$\n\nwhere\n\n$$\nSE_{z} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\n$$\n\nIf we do not have a large sample, we can use the t-distribution with the formula:\n\n$$\n(\\bar{X}_1 - \\bar{X}_2) \\;\\pm\\; t_{\\alpha/2,\\,df} \\cdot SE_{\\text{pooled}}\n$$\n\nPutting this together, we get the confidence interval for the mean difference.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define the components of the formula\nx_bar_tg <- mean(df_data$lsas_post[df_data$trt == \"therapist-guided\"], na.rm = T)\nx_bar_sg <- mean(df_data$lsas_post[df_data$trt == \"self-guided\"], na.rm = T)\ns_2_tg <- var(df_data$lsas_post[df_data$trt == \"therapist-guided\"], na.rm = T)\ns_2_sg <- var(df_data$lsas_post[df_data$trt == \"self-guided\"], na.rm = T)\nn_tg <- sum(!is.na(df_data$lsas_post[df_data$trt == \"therapist-guided\"])) # here we only count the number of persons that provided data\nn_sg <- sum(!is.na(df_data$lsas_post[df_data$trt == \"self-guided\"])) # here we only count the number of persons that provided data\nse_z <- sqrt((s_2_tg / n_tg) + (s_2_sg / n_sg)) # save the SE of the difference as a separate object for conveninence\nsp2 <- ((n_tg - 1) * s_2_tg + (n_sg - 1) * s_2_sg) / (n_tg + n_sg - 2) # pooled variance\nSE_pooled <- sqrt(sp2 * (1 / n_tg + 1 / n_sg)) # pooled standard error\n\n# and put it together with the z-value formula\n\nucl <- (x_bar_sg - x_bar_tg) + 1.96 * se_z\nlcl <- (x_bar_sg - x_bar_tg) - 1.96 * se_z\nprint(c(lcl, ucl))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.6967551 15.8176128\n```\n\n\n:::\n\n```{.r .cell-code}\n# or the t-value formula\ndf <- n_sg + n_tg - 2\nalpha <- 0.05\nt_crit <- qt(1 - alpha / 2, df)\nucl <- (x_bar_sg - x_bar_tg) + t_crit * SE_pooled\nlcl <- (x_bar_sg - x_bar_tg) - t_crit * SE_pooled\nprint(c(lcl, ucl))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.7676792 15.8885369\n```\n\n\n:::\n:::\n\n\nThe confidence interval from the t-distribution is also given by the `t.test()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(lsas_post ~ trt,\n  data = df_data[df_data$trt != \"waitlist\", ],\n  var.equal = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  lsas_post by trt\nt = 1.7993, df = 109, p-value = 0.07474\nalternative hypothesis: true difference in means between group self-guided and group therapist-guided is not equal to 0\n95 percent confidence interval:\n -0.7676792 15.8885369\nsample estimates:\n     mean in group self-guided mean in group therapist-guided \n                      64.91228                       57.35185 \n```\n\n\n:::\n:::\n\n\n::: {#exr-independent-means .callout-caution collapse=\"true\"}\n## Testing independent group means\n\n1.  Calculate the mean difference in post-treatment LSAS scores, and the associated two-sided p-value for the mean difference between the therapist-guided and the wait list group\n2.  Complement this with a 95% confidence interval.\n3.  Do you think the assumption of equal variance between the groups is justifies?\n4.  Do you think the assumptions of the t-test are fulfilled?\n5.  How do the results differ if you use the Welch t-test instead\n6.  **BONUS:** If you feel up to it, try to also calculate a z-test for the mean difference in post-treatment LSAS-scores using the formulas above\n7.  **BONUS:** Modify the code above to calculate the 99% confidence interval of the mean difference in LSAS-scores at post-treatment between the self-guided and the therapist-guided groups\n:::\n\n## Testing dependent means\n\nThe independent group t-test assumes that the groups compared are independent, which is the case for the two treatment groups. Sometimes, however, we want to compare the means of dependent groups. This could be for instance the difference in means between two time-point of the same group. Then we can use a paired-sample t-test.\n\nFor a paired samples *t*-test, the statistic is:\n\n$$\nt = \\frac{\\bar{D}}{SE_D}\n$$\n\nwhere:\n\n-   $\\bar{D}$ = mean of the difference scores\n-   $SE_D$ = the standard error of the difference scores calculated as $s_D/ \\sqrt{n}$ = the standard error of the differences, with $s_D$ = the standard deviation of the differences and $n$ = the number of paired observations\n\nLet's use this to formula to test the difference in LSAS-scores from pre-to post-treatment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiff_pre_post <- df_data$lsas_post - df_data$lsas_screen\nmean_diff <- mean(diff_pre_post, na.rm = TRUE)\nsd_diff <- sd(diff_pre_post, na.rm = TRUE)\nn <- sum(!is.na(diff_pre_post))\nse_diff <- sd_diff / sqrt(n)\nt_value <- mean_diff / se_diff\nt_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -11.07385\n```\n\n\n:::\n:::\n\n\nAnd get the two-tailed p-value from this as before\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- n - 1\np_value <- 2 * (1 - pt(abs(t_value), df))\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\nOr using the `t.test()` function with the the argument `paired = TRUE`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(df_data$lsas_post, df_data$lsas_screen, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  df_data$lsas_post and df_data$lsas_screen\nt = -11.074, df = 168, p-value < 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -21.05556 -14.68409\nsample estimates:\nmean difference \n      -17.86982 \n```\n\n\n:::\n:::\n\n\nWe can also get the confidence intervals of this difference, using a familiar formula for large samples\n\n$$\n\\bar{D} \\;\\pm\\; z_{\\alpha/2} \\cdot SE_D\n$$\n\nFor smaller samples, we need use the t-distribution and find the right t-value for our degrees of freedom and coverage interval.\n\n$$\nCI = \\bar{D} \\;\\pm\\; t_{\\alpha/2, \\, df} \\cdot SE_D\n$$\n\nAnd again, $SE_D = {s_D}/ {\\sqrt{n}}$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiff_pre_post <- df_data$lsas_post - df_data$lsas_screen\nmean_diff <- mean(diff_pre_post, na.rm = TRUE)\nsd_diff <- sd(diff_pre_post, na.rm = TRUE)\nn <- sum(!is.na(diff_pre_post))\nse_diff <- (sd_diff / sqrt(n)) # saving the standard error of the difference as a separate object for convenience\n\n# and putting it together\nlcl <- mean_diff - 1.96 * se_diff\nucl <- mean_diff + 1.96 * se_diff\nprint(c(lcl, ucl))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -21.03267 -14.70698\n```\n\n\n:::\n:::\n\n\nor manually using the t-values\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- n - 1\nalpha <- 0.05\nt_crit <- qt(1 - alpha / 2, df)\nlcl <- mean_diff - t_crit * se_diff\nucl <- mean_diff + t_crit * se_diff\nprint(c(lcl, ucl))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -21.05556 -14.68409\n```\n\n\n:::\n:::\n\n\nOr again, more conveniently using the `t.test()` function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(df_data$lsas_post, df_data$lsas_screen, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  df_data$lsas_post and df_data$lsas_screen\nt = -11.074, df = 168, p-value < 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -21.05556 -14.68409\nsample estimates:\nmean difference \n      -17.86982 \n```\n\n\n:::\n:::\n\n\n::: {#exr-dependent-means .callout-caution collapse=\"true\"}\n## Testing dependent group means\n\n1.  Compute a t-test for the difference in LSAS-scores between post-treatment and 12-month follow-up and provide an interpretation of its meaning\n2.  Also calculate the 95% confidence interval for this difference, using the z-value formula and provide an interpretation of its meaning\n3.  Compare the means of GAD-7 from pre- to post-treatment and interpret the results\n:::\n\n## Contingency tables and the Chi-squared test\n\nSay that we wanted to test the distribution of some categorical variable across two groups, the the methods presented above will not help. For this we need other tests.\n\nSay that we wanted to know if the gender distribution was similar across in the self-guided as in the therapist-guided treatment group of the the STEpS study. The first step to such an investigation would be to create a *contingency table* showing the gender distribution across the groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a gender variable\ndf_data$gender <- rbinom(nrow(df_data), 1, 0.7)\ndf_data$gender <- ifelse(df_data$gender == 1, \"Woman\", \"Man\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(df_data$trt, df_data$gender) # number of person\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  \n                   Man Woman\n  self-guided       14    47\n  therapist-guided  23    37\n  waitlist          20    40\n```\n\n\n:::\n\n```{.r .cell-code}\nprop.table(table(df_data$trt, df_data$gender), margin = 1) # proportion in each treatment group\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  \n                         Man     Woman\n  self-guided      0.2295082 0.7704918\n  therapist-guided 0.3833333 0.6166667\n  waitlist         0.3333333 0.6666667\n```\n\n\n:::\n:::\n\n\nWe see that there are some small differences between the groups, but we have no statistical test of these differences. Say that we wanted to test the null hypothesis that there is no association between gender and the treatment group you end up in. This hypothesis should hold, due to the randomization of the STEpS study.\n\nOne way to test if the proportion of men and women differs between the groups is perform a **Chi-squared test (**$X^2-test$**).**\n\nThe formula for Chi-squared test statistic is:\n\n$$\n\\chi^2 = \\sum_{i=1}^{r} \\sum_{j=1}^{c} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n$$\n\nwhere\n\n$$\nE_{ij} = \\frac{(\\text{row total})_i \\cdot (\\text{column total})_j}{\\text{grand total}}\n$$\n\nThis test compares the observed counts in each cell against what would be expected if values where distributed equally across the groups (i.e. across the cells of the contingency table). Coding this formula manually is a bit tricky, but here is the code for those interested.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Build the contingency table\ntbl <- table(trt = df_data$trt, gender = df_data$gender)\n\n## Convert this table to matrix format for the following calculations\nO <- as.matrix(tbl)\nO\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  gender\ntrt                Man Woman\n  self-guided       14    47\n  therapist-guided  23    37\n  waitlist          20    40\n```\n\n\n:::\n\n```{.r .cell-code}\n## Expected counts E_ij = (row total_i * col total_j) / grand total\nrow_tot <- rowSums(O)\ncol_tot <- colSums(O)\ngrand <- sum(O)\nE <- outer(row_tot, col_tot) / grand # outer is a function to multiply arayys\nE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                      Man    Woman\nself-guided      19.20994 41.79006\ntherapist-guided 18.89503 41.10497\nwaitlist         18.89503 41.10497\n```\n\n\n:::\n\n```{.r .cell-code}\n## Chi-square statistic: sum_{i,j} (O_ij - E_ij)^2 / E_ij\nchi_sq <- sum((O - E)^2 / E)\n\n## Degrees of freedom: (r - 1)(c - 1)\nr <- nrow(O)\nc <- ncol(O)\ndf <- (r - 1) * (c - 1)\n\n## p-value from chi-square distribution\np_value <- pchisq(chi_sq, df = df, lower.tail = FALSE)\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1774092\n```\n\n\n:::\n:::\n\n\nIn R, these calculations can be easily performed using the function `chisq.test()` that also provide tables for the observed and expected frequencies\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(df_data$trt, df_data$gender)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  df_data$trt and df_data$gender\nX-squared = 3.4586, df = 2, p-value = 0.1774\n```\n\n\n:::\n\n```{.r .cell-code}\nchisq.test(df_data$trt, df_data$gender)$observed\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  df_data$gender\ndf_data$trt        Man Woman\n  self-guided       14    47\n  therapist-guided  23    37\n  waitlist          20    40\n```\n\n\n:::\n\n```{.r .cell-code}\nchisq.test(df_data$trt, df_data$gender)$expected\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  df_data$gender\ndf_data$trt             Man    Woman\n  self-guided      19.20994 41.79006\n  therapist-guided 18.89503 41.10497\n  waitlist         18.89503 41.10497\n```\n\n\n:::\n:::\n\n\nOur results tells us that the null hypothesis of no association cannot be rejected. In other words, our data would not be unexpected if there was no association between gender and treatment group in the underlying population (kind of a strange though experiment, as there are only treatment variables in treatment studies, not in the underlying population).\n\n::: callout-caution\nThe **Chi-squared test** is only valid if the counts in each cell is \\>5. When cell counts are lower, Fisher's exact test should be used instead. You can use the `fisher.test()` function\n:::\n\n::: {#exr-testing-categorical-distributions .callout-warning collapse=\"true\"}\n## Testing categorical distributions\n\nChi-squared tests, and other tests of significance, are sometimes used to check that important pre-treatment characteristics, such as gender or symptom level, are balanced between the treatment groups. Non-sinificant p-values are then taken as an argument that the groups are balanced. Reason about why this is a problematic approach.\n\nCreate a categorical for high or low generalized anxiety and one for high and low social anxiety, and use the Chi squared test to test the null hypothesis of no association between the variables\n:::\n\n## Other non-parametric tests\n\nThere are a number of other non-parametric tests that can be used if our data does not fulfill the assumptions for parametric tests, like t-tests and z-tests. We won't go through the formulas for all these, but show you how they can be implemented in R.\n\n### Sign test\n\nThe sign test is used to test whether the **median** of paired differences equals a hypothesized value (often 0), using only the **signs** of differences, (i.e. + or -). This test can be used even when the sample is small, and the underlying population distribution is assumed to be non-normal.\n\nThe test is performed by counting how often a difference between pairs of values are positive. If there was no systematic change, this should occur 50% of the time. We then test whether our actual proportion of positive signs is likely to come from an underlying population where 50% of the signs are positive.\n\nWe could use it to test the nyll hypothesis that the median difference of LSAS-score at between pre-treatment and post-treatment is 0 (analog to our paired t-test above).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Paired sign test: H0 median LSAS(pre - post) = 0\ndiff_pre_post <- df_data$lsas_post - df_data$lsas_screen # create differnece scores\nn <- sum(diff_pre_post != 0, na.rm = TRUE) # exclude ties (exact zeros)\ns <- sum(diff_pre_post[diff_pre_post != 0] > 0, na.rm = TRUE) # number of positive differences (again excluding ties)\nbinom.test(s, n, p = 0.5, alternative = \"two.sided\") # a test of the proportion\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tExact binomial test\n\ndata:  s and n\nnumber of successes = 24, number of trials = 167, p-value < 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.0943006 0.2062463\nsample estimates:\nprobability of success \n             0.1437126 \n```\n\n\n:::\n:::\n\n\nThis null hypothesis seems very unlikely.\n\n### Wilcoxon signed rank test\n\nTests if the **distribution of paired differences** is symmetric around 0 (often framed as median difference = 0), using magnitudes and signs.\\\n\n**Assumptions:** Paired observations; differences are symmetrically distributed.\n\n**Pro's:** Unlike the t-test, it does not assume interval level data. It is also better powered that the sign test.\n\nWe can use this to test the null hypothesis that the median LSAS score is the same at post-treatment as at pre-treatment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(df_data$lsas_post, df_data$lsas_screen,\n  paired = TRUE,\n  alternative = \"two.sided\",\n  exact = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  df_data$lsas_post and df_data$lsas_screen\nV = 1310, p-value < 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\nAgain, the null hypothesis seems very unlikely.\n\n### Wilcox rank-sum test\n\nThis test, aslo known as the Mann-Whitney U-test, test whether two **independent** samples come from the same distribution (often interpreted as a shift in location/medians).\\\n\n**Assumptions:** Independent samples; similar shapes are helpful for a “median shift” interpretation.\n\nUnlike the independent groups t-test, it does not assume interval level data. We can use this test to test the null hypothesis that LSAS scores at post-treatment have the same distribution in the self-guided and the therapist-guided treatment groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Two-sample Wilcoxon rank-sum test (unpaired)\n\nwilcox.test(lsas_post ~ trt,\n  data = df_data,\n  subset = trt %in% c(\"self-guided\", \"therapist-guided\"),\n  exact = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  lsas_post by trt\nW = 1872, p-value = 0.04974\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\n::: {#exr-non-parametric-tests .callout-warning collapse=\"true\"}\n## Non-parametric tests\n\nWhich of all the test performed today do you think is most appropriate for the pre-post difference in LSAS scores?\n\nAnd which of all tests performed is most appropriate for comparing the LSAS scores between the self-guided and the therapist-guided groups?\n\nPerform a signed test for the pre-post difference in DERS scores and interpret the results.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}