{
  "hash": "9b1d5917577f5cb0012405b167529253",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab: Power and Sample Size\"\nnumber-sections: true\nformat: live-html\nengine: knitr\nwebr:\n  packages:\n    - dplyr\n    - tidyr\n    - purrr\n    - pwr\n    - ggplot2\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell edit='false'}\n```{webr}\n#| edit: false\n#| output: false\nwebr::install(\"gradethis\", quiet = TRUE)\nlibrary(gradethis)\noptions(webr.exercise.checker = function(\n  label, user_code, solution_code, check_code, envir_result, evaluate_result,\n  envir_prep, last_value, engine, stage, ...\n) {\n  if (is.null(check_code)) {\n    # No grading code, so just skip grading\n    invisible(NULL)\n  } else if (is.null(label)) {\n    list(\n      correct = FALSE,\n      type = \"warning\",\n      message = \"All exercises must have a label.\"\n    )\n  } else if (is.null(solution_code)) {\n    list(\n      correct = FALSE,\n      type = \"warning\",\n      message = htmltools::tags$div(\n        htmltools::tags$p(\"A problem occurred grading this exercise.\"),\n        htmltools::tags$p(\n          \"No solution code was found. Note that grading exercises using the \",\n          htmltools::tags$code(\"gradethis\"),\n          \"package requires a model solution to be included in the document.\"\n        )\n      )\n    )\n  } else {\n    gradethis::gradethis_exercise_checker(\n      label = label, solution_code = solution_code, user_code = user_code,\n      check_code = check_code, envir_result = envir_result,\n      evaluate_result = evaluate_result, envir_prep = envir_prep,\n      last_value = last_value, stage = stage, engine = engine)\n  }\n})\n```\n:::\n\n\n\nIn this lab, we'll explore the basics of power analysis. We'll use the `pwr` package to calculate power for a planned study.\n\n::: {.callout-tip}\nWhile you can complete all the exercises in your browser, we recommend also practicing in RStudio. Using an editor like RStudio will help you build real-world skills for writing, running, and saving your R code.\n:::\n\n\n# Calculate power for a planned study using the `pwr` package\n\nThe `pwr` package provides functions for power analysis. For two-group t-tests, we use `pwr.t.test()`.\n\n:::: {.panel-tabset}\n\n## Problem \n\nSuppose you're planning a study comparing two groups with:\n\n- Sample size of 30 per group (`n = 30`)\n- Expected Cohen's d effect size of 0.5\n- Significance level of 0.05 (`sig.level = 0.05`)\n- Two-sided test (`alternative = \"two.sided\"`)\n\nUse `pwr.t.test()` to calculate the statistical power.\n\n\n::: {.cell exercise='ex_1'}\n```{webr}\n#| label: ex-1\n#| exercise: ex_1\nlibrary(pwr)\n\n# Calculate power\nresult <- pwr.t.test(\n  n = ______,\n  d = ______,\n  sig.level = ______,\n  alternative = ______\n)\n\n# Print the result\nresult\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_1\"}\n\nThe `pwr.t.test()` function takes these arguments:\n\n- `n`: sample size per group\n- `d`: Cohen's d effect size\n- `sig.level`: alpha level\n- `alternative`: \"two.sided\", \"greater\", or \"less\"\n\nLeave `power` blank - that's what you're calculating!\n\n```r\npwr.t.test(\n  n = 30,\n  d = 0.5,\n  sig.level = ______,\n  alternative = \"two.sided\"\n)\n```\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_1\"}\n\n\n::: {.cell exercise='ex_1' solution='true'}\n```{webr}\n#| exercise: ex_1\n#| label: ex-1-solution\n#| solution: true\nlibrary(pwr)\n\n# Calculate power\nresult <- pwr.t.test(\n  n = 30,           #<1>\n  d = 0.5,          #<2>\n  sig.level = 0.05, #<3>\n  alternative = \"two.sided\" #<4>\n)\n\n# Print the result\nresult\n```\n:::\n\n1. Sample size per group\n2. Expected Cohen's d effect size (medium effect)\n3. Significance level (alpha = 0.05)\n4. Two-sided hypothesis test\n\nWith these parameters, the power is approximately 0.47 (47%), which is below the conventional 0.80 threshold.\n\n:::\n\n\n::: {.cell exercise='ex_1' check='true'}\n```{webr}\n#| exercise: ex_1\n#| label: ex-1-gradethis\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n# Sample Size Calculation\n\nOften, we want to determine how many participants we need to achieve adequate power (typically 80%).\n\n::: {#exr-sample-size}\n## Calculate required sample size\n:::\n\n:::: {.panel-tabset}\n## Problem\n\nFor the same study design (Cohen's d = 0.5, alpha = 0.05, two-sided test), calculate the sample size needed to achieve 80% power.\n\nThis time, leave `n` blank and specify `power = 0.80`.\n\n\n::: {.cell exercise='ex_2'}\n```{webr}\n#| label: ex-2\n#| exercise: ex_2\nlibrary(pwr)\n\n# Calculate required sample size\nresult <- pwr.t.test(\n  d = ______,\n  sig.level = ______,\n  power = ______,\n  alternative = \"two.sided\"\n)\n\n# Print the result\nresult\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_2\"}\n\nNow you're solving for `n` instead of `power`, so:\n\n- Leave `n` out completely\n- Add `power = 0.80`\n- Keep the other parameters the same\n\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_2\"}\n\n\n::: {.cell exercise='ex_2' solution='true'}\n```{webr}\n#| label: ex-2-solution\n#| exercise: ex_2\n#| solution: true\nlibrary(pwr)\n\n# Calculate required sample size\nresult <- pwr.t.test(\n  d = 0.5,          #<1>\n  sig.level = 0.05,\n  power = 0.80,     #<2>\n  alternative = \"two.sided\"\n)\n\n# Print the result\nresult\n```\n:::\n\n1. Expected Cohen's d effect size\n2. Desired power (80%)\n\nYou need approximately 64 participants per group (128 total) to achieve 80% power for detecting a medium effect size.\n\n:::\n\n\n::: {.cell exercise='ex_2' check='true'}\n```{webr}\n#| label: ex-2-gradethis\n#| exercise: ex_2\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n# How Effect Size Changes Power\n\nEffect size is a critical factor in power analysis. Cohen's d describes the standardized difference between two groups:\n\n- **Small effect**: d = 0.2\n- **Medium effect**: d = 0.5\n- **Large effect**: d = 0.8\n\nLet's explore how effect size impacts power when sample size is held constant.\n\n::: {#exr-effect-compare}\n## Compare power across different effect sizes\n:::\n\n:::: {.panel-tabset}\n## Problem\n\nCalculate the power for detecting small (d = 0.2), medium (d = 0.5), and large (d = 0.8) effects with:\n\n- Sample size: 50 per group\n- Significance level: 0.05\n- Two-sided test\n\nStore the results in variables and compare them.\n\n\n::: {.cell exercise='ex_3a'}\n```{webr}\n#| label: ex-3a\n#| exercise: ex_3a\nlibrary(pwr)\n\n# Calculate power for small effect\npower_small <- pwr.t.test(\n  n = 50,\n  d = ______,\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)$power\n\n# Calculate power for medium effect\npower_medium <- pwr.t.test(\n  n = 50,\n  d = ______,\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)$power\n\n# Calculate power for large effect\npower_large <- pwr.t.test(\n  n = 50,\n  d = ______,\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)$power\n\n# Display results\ncat(\"Power for small effect (d = 0.2):\", round(power_small, 3), \"\\n\")\ncat(\"Power for medium effect (d = 0.5):\", round(power_medium, 3), \"\\n\")\ncat(\"Power for large effect (d = 0.8):\", round(power_large, 3), \"\\n\")\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_3a\"}\n\nUse Cohen's conventional effect sizes:\n\n- Small: d = 0.2\n- Medium: d = 0.5\n- Large: d = 0.8\n\nEach `pwr.t.test()` call should only differ in the `d` parameter.\n\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_3a\"}\n\n\n::: {.cell exercise='ex_3a' solution='true'}\n```{webr}\n#| label: ex-3a-solution\n#| exercise: ex_3a\n#| solution: true\nlibrary(pwr)\n\n# Calculate power for small effect\npower_small <- pwr.t.test(\n  n = 50,\n  d = 0.2,  #<1>\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)$power\n\n# Calculate power for medium effect\npower_medium <- pwr.t.test(\n  n = 50,\n  d = 0.5,  #<2>\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)$power\n\n# Calculate power for large effect\npower_large <- pwr.t.test(\n  n = 50,\n  d = 0.8,  #<3>\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)$power\n\n# Display results\ncat(\"Power for small effect (d = 0.2):\", round(power_small, 3), \"\\n\")\ncat(\"Power for medium effect (d = 0.5):\", round(power_medium, 3), \"\\n\")\ncat(\"Power for large effect (d = 0.8):\", round(power_large, 3), \"\\n\")\n```\n:::\n\n1. Small effect size (d = 0.2) - only ~29% power\n2. Medium effect size (d = 0.5) - ~70% power\n3. Large effect size (d = 0.8) - ~95% power\n\nNotice how dramatically power increases with effect size! With n=50, we have excellent power for large effects, decent power for medium effects, but poor power for small effects.\n\n:::\n\n\n::: {.cell exercise='ex_3a' check='true'}\n```{webr}\n#| label: ex-3a-gradethis\n#| exercise: ex_3a\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n::: {#exr-effect-visualize}\n## Visualize effect size and power relationship\n:::\n\n:::: {.panel-tabset}\n## Problem\n\nCreate a plot showing how power changes across a range of effect sizes (d = 0.1 to 1.0) for a fixed sample size of 50 per group.\n\n\n::: {.cell exercise='ex_3b'}\n```{webr}\n#| label: ex-3b\n#| exercise: ex_3b\nlibrary(pwr)\nlibrary(ggplot2)\nlibrary(purrr)\n\n# Create a sequence of effect sizes\neffect_sizes <- seq(0.1, 1.0, by = 0.05)\n\n# Calculate power for each effect size and create data frame\npower_df <- map(\n  effect_sizes,\n  \\(d) {\n    result <- pwr.t.test(\n      n = ______,\n      d = ______,\n      sig.level = 0.05,\n      alternative = \"two.sided\"\n    )\n    data.frame(\n      effect_size = d,\n      power = result$power\n    )\n  }\n) |> list_rbind()\n\n# Plot\nggplot(power_df, aes(x = effect_size, y = power)) +\n  geom_line(color = \"darkgreen\", linewidth = 1) +\n  geom_hline(yintercept = 0.80, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = c(0.2, 0.5, 0.8), linetype = \"dotted\", alpha = 0.5) +\n  annotate(\"text\", x = 0.2, y = 0.05, label = \"Small\", size = 3) +\n  annotate(\"text\", x = 0.5, y = 0.05, label = \"Medium\", size = 3) +\n  annotate(\"text\", x = 0.8, y = 0.05, label = \"Large\", size = 3) +\n  labs(\n    title = \"Power vs Effect Size (n = 50 per group)\",\n    x = \"Cohen's d (Effect Size)\",\n    y = \"Statistical Power\"\n  ) +\n  theme_minimal()\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_3b\"}\n\nIn the `map()` function, `d` is the iterator variable representing each effect size. The sample size should be 50.\n\n```r\npower_df <- map(\n  effect_sizes,\n  \\(d) {\n    result <- pwr.t.test(\n      n = 50,\n      d = d,  # Use the iterator variable\n      sig.level = 0.05,\n      alternative = \"two.sided\"\n    )\n    data.frame(\n      effect_size = d,\n      power = result$power\n    )\n  }\n) |> list_rbind()\n```\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_3b\"}\n\n\n::: {.cell exercise='ex_3b' solution='true'}\n```{webr}\n#| label: ex-3b-solution\n#| exercise: ex_3b\n#| solution: true\nlibrary(pwr)\nlibrary(ggplot2)\nlibrary(purrr)\n\n# Create a sequence of effect sizes\neffect_sizes <- seq(0.1, 1.0, by = 0.05)\n\n# Calculate power for each effect size and create data frame\npower_df <- map(\n  effect_sizes,\n  \\(d) {\n    result <- pwr.t.test(\n      n = 50,   #<1>\n      d = d,    #<2>\n      sig.level = 0.05,\n      alternative = \"two.sided\"\n    )\n    data.frame(\n      effect_size = d,\n      power = result$power\n    )\n  }\n) |> list_rbind()  #<3>\n\n# Plot\nggplot(power_df, aes(x = effect_size, y = power)) +\n  geom_line(color = \"darkgreen\", linewidth = 1) +\n  geom_hline(yintercept = 0.80, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = c(0.2, 0.5, 0.8), linetype = \"dotted\", alpha = 0.5) +\n  annotate(\"text\", x = 0.2, y = 0.05, label = \"Small\", size = 3) +\n  annotate(\"text\", x = 0.5, y = 0.05, label = \"Medium\", size = 3) +\n  annotate(\"text\", x = 0.8, y = 0.05, label = \"Large\", size = 3) +\n  labs(\n    title = \"Power vs Effect Size (n = 50 per group)\",\n    x = \"Cohen's d (Effect Size)\",\n    y = \"Statistical Power\"\n  ) +\n  theme_minimal()\n```\n:::\n\n1. Fixed sample size of 50 per group\n2. Effect size varies from the sequence\n3. Combine list of data frames into a single data frame\n\nThe plot shows that with n=50, you cross the 80% power threshold (red dashed line) at approximately d = 0.57 (between medium and large effects). The vertical dotted lines show conventional effect size benchmarks.\n\n:::\n\n\n::: {.cell exercise='ex_3b' check='true'}\n```{webr}\n#| label: ex-3b-gradethis\n#| exercise: ex_3b\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n# Power Curves\n\nA power curve shows how power changes with sample size for a given effect size.\n\n::: {#exr-power-curve}\n## Create a power curve\n:::\n\n:::: {.panel-tabset}\n## Problem\n\nCalculate power for sample sizes ranging from 10 to 100 (per group) for Cohen's d = 0.5, then create a plot.\n\n\n::: {.cell exercise='ex_3'}\n```{webr}\n#| label: ex-3\n#| exercise: ex_3\nlibrary(pwr)\nlibrary(ggplot2)\nlibrary(purrr)\n\n# Create a sequence of sample sizes\nsample_sizes <- seq(10, 100, by = 5)\n\n# Calculate power for each sample size and create data frame\npower_df <- map(\n  sample_sizes,\n  \\(n) {\n    result <- pwr.t.test(\n      n = ______,\n      d = ______,\n      sig.level = 0.05,\n      alternative = \"two.sided\"\n    )\n    data.frame(\n      n = n,\n      power = result$power\n    )\n  }\n) |> list_rbind()\n\n# Plot\nggplot(power_df, aes(x = n, y = power)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  geom_hline(yintercept = 0.80, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Power Curve for Two-Sample t-test\",\n    x = \"Sample Size per Group\",\n    y = \"Statistical Power\"\n  ) +\n  theme_minimal()\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_3\"}\n\nIn the `map()` function, `n` is the iterator variable from the function, so use it directly. The effect size should be 0.5.\n\n```r\npower_df <- map(\n  sample_sizes,\n  \\(n) {\n    result <- pwr.t.test(\n      n = n,\n      d = 0.5,\n      sig.level = 0.05,\n      alternative = \"two.sided\"\n    )\n    data.frame(\n      n = n,\n      power = result$power\n    )\n  }\n) |> list_rbind()\n```\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_3\"}\n\n\n::: {.cell exercise='ex_3' solution='true'}\n```{webr}\n#| label: ex-3-solution\n#| exercise: ex_3\n#| solution: true\nlibrary(pwr)\nlibrary(ggplot2)\nlibrary(purrr)\n\n# Create a sequence of sample sizes\nsample_sizes <- seq(10, 100, by = 5)\n\n# Calculate power for each sample size and create data frame\npower_df <- map(\n  sample_sizes,\n  \\(n) {\n    result <- pwr.t.test(\n      n = n,            #<1>\n      d = 0.5,          #<2>\n      sig.level = 0.05,\n      alternative = \"two.sided\"\n    )\n    data.frame(\n      n = n,\n      power = result$power\n    )\n  }\n) |> list_rbind()  #<3>\n\n# Plot\nggplot(power_df, aes(x = n, y = power)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  geom_hline(yintercept = 0.80, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Power Curve for Two-Sample t-test\",\n    x = \"Sample Size per Group\",\n    y = \"Statistical Power\"\n  ) +\n  theme_minimal()\n```\n:::\n\n1. Use the sample size from the iterator\n2. Cohen's d effect size\n3. Combine list of data frames into a single data frame\n\nThe red dashed line shows 80% power. Notice how power increases with sample size!\n\n:::\n\n\n::: {.cell exercise='ex_3' check='true'}\n```{webr}\n#| label: ex-3-gradethis\n#| exercise: ex_3\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n::: {#exr-power-comparison}\n## Compare power curves across multiple effect sizes\n:::\n\n:::: {.panel-tabset}\n## Problem\n\nCreate a plot showing power curves for small (0.2), medium (0.5), and large (0.8) effect sizes simultaneously. Vary sample size from 10 to 150 (by 5) for each effect size.\n\nUse `expand_grid()` to create all combinations of effect sizes and sample sizes, then use `map2_dbl()` to calculate power for each combination.\n\n\n::: {.cell exercise='ex_3c'}\n```{webr}\n#| label: ex-3c\n#| exercise: ex_3c\nlibrary(pwr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(tidyr)\n\n# Define effect sizes and sample sizes\neffect_sizes <- c(0.2, 0.5, 0.8)\nsample_sizes <- seq(10, 150, by = 5)\n\n# Create all combinations and calculate power\npower_comparison <- expand_grid(\n  n = ______,\n  d = ______\n) |>\n  mutate(\n    power = map2_dbl(\n      d, n,\n      \\(d, n) {\n        pwr.t.test(\n          d = ______,\n          n = ______,\n          sig.level = 0.05,\n          alternative = \"two.sided\"\n        )$power\n      }\n    ),\n    effect_label = factor(\n      d,\n      levels = c(0.2, 0.5, 0.8),\n      labels = c(\"Small (d=0.2)\", \"Medium (d=0.5)\", \"Large (d=0.8)\")\n    )\n  )\n\n# Create the comparison plot\nggplot(power_comparison, aes(x = n, y = power, color = effect_label)) +\n  geom_line(linewidth = 1) +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", alpha = 0.7) +\n  labs(\n    title = \"Power Curves for Different Effect Sizes\",\n    subtitle = \"Two-sample t-test, α = 0.05\",\n    x = \"Sample Size per Group\",\n    y = \"Statistical Power\",\n    color = \"Effect Size\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(limits = c(0, 1))\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_3c\"}\n\n`expand_grid()` creates all combinations of the vectors you provide.\n\nIn `map2_dbl()`, the first two arguments are the vectors to iterate over in parallel. Use the function parameters `d` and `n` in the `pwr.t.test()` call.\n\n```r\npower_comparison <- expand_grid(\n  n = sample_sizes,\n  d = effect_sizes\n) |>\n  mutate(\n    power = map2_dbl(\n      d, n,\n      \\(d, n) {\n        pwr.t.test(\n          d = d,  # Use the iterator variable\n          n = n,  # Use the iterator variable\n          sig.level = 0.05,\n          alternative = \"two.sided\"\n        )$power\n      }\n    ),\n    # ... rest of code\n```\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_3c\"}\n\n\n::: {.cell exercise='ex_3c' solution='true'}\n```{webr}\n#| label: ex-3c-solution\n#| exercise: ex_3c\n#| solution: true\nlibrary(pwr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(tidyr)\n\n# Define effect sizes and sample sizes\neffect_sizes <- c(0.2, 0.5, 0.8)\nsample_sizes <- seq(10, 150, by = 5)\n\n# Create all combinations and calculate power\npower_comparison <- expand_grid(\n  n = sample_sizes,   #<1>\n  d = effect_sizes    #<2>\n) |>\n  mutate(\n    power = map2_dbl(\n      d, n,             #<3>\n      \\(d, n) {\n        pwr.t.test(\n          d = d,        #<4>\n          n = n,        #<5>\n          sig.level = 0.05,\n          alternative = \"two.sided\"\n        )$power\n      }\n    ),\n    effect_label = factor(\n      d,\n      levels = c(0.2, 0.5, 0.8),\n      labels = c(\"Small (d=0.2)\", \"Medium (d=0.5)\", \"Large (d=0.8)\")\n    )\n  )\n\n# Create the comparison plot\nggplot(power_comparison, aes(x = n, y = power, color = effect_label)) +\n  geom_line(linewidth = 1) +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", alpha = 0.7) +\n  labs(\n    title = \"Power Curves for Different Effect Sizes\",\n    subtitle = \"Two-sample t-test, α = 0.05\",\n    x = \"Sample Size per Group\",\n    y = \"Statistical Power\",\n    color = \"Effect Size\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(limits = c(0, 1))\n```\n:::\n\n1. Sample sizes to iterate over\n2. Effect sizes to iterate over\n3. `map2_dbl()` iterates over two vectors in parallel\n4. Use effect size from the iterator\n5. Use sample size from the iterator\n\nThe plot shows three power curves, one for each effect size. Key insights:\n\n- Small effects require much larger samples to achieve 80% power (n ≈ 393 per group)\n- Medium effects need n ≈ 64 per group for 80% power\n- Large effects only need n ≈ 26 per group for 80% power\n\nThe dashed line at 0.8 helps identify the minimum sample size needed for adequate power for each effect size.\n\n:::\n\n\n::: {.cell exercise='ex_3c' check='true'}\n```{webr}\n#| label: ex-3c-gradethis\n#| exercise: ex_3c\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n# Simulation-Based Power Analysis\n\nAnalytical formulas (like `pwr.t.test()`) are great, but sometimes we need to verify power through simulation. This is especially useful for complex designs or when assumptions may be violated. Simulation is also useful for checking your understanding of the concepts.\n\n## Understanding the Simulation Approach\n\nInstead of using formulas, we can:\n\n1. Simulate many datasets under specific conditions (effect size, sample size)\n2. Run a t-test on each simulated dataset\n3. Save key statistics (p-value, confidence interval, effect size, etc.)\n4. Calculate power = proportion of significant tests\n\n::: {#exr-simulate}\n## Create a simulation function\n:::\n\n:::: {.panel-tabset}\n## Problem\n\nCreate a function that runs many simulated studies and captures comprehensive results from each one. The function should:\n\n- Generate data for two groups with specified sample size and effect size\n- Run a t-test on each simulated dataset\n- Store p-values, confidence intervals, effect sizes, and other statistics\n\n\n::: {.cell exercise='ex_4' envir='sim_env' timelimit='300' persist='true'}\n```{webr}\n#| label: ex-4\n#| exercise: ex_4\n#| envir: sim_env\n#| timelimit: 300\n#| persist: true\n# Function to simulate a single study\nsimulate_study <- function(n_per_group, effect_size) {\n  data.frame(\n    group = rep(c(\"Control\", \"Treatment\"), each = n_per_group),\n    score = c(\n      rnorm(n_per_group, mean = 0, sd = 1),\n      rnorm(n_per_group, mean = ______, sd = 1)\n    )\n  )\n}\n\n# Function to run many simulated studies\nrun_power_simulation <- function(\n    n_per_group,\n    effect_size,\n    n_simulations = 1000,\n    alpha = 0.05) {\n  \n  # Create storage for results\n  results <- data.frame(\n    simulation = 1:n_simulations,\n    p_value = numeric(n_simulations),\n    ci_lower = numeric(n_simulations),\n    ci_upper = numeric(n_simulations),\n    significant = logical(n_simulations),\n    effect = numeric(n_simulations)\n  )\n  \n  # Run many simulated studies\n  for (i in 1:n_simulations) {\n    # Simulate data\n    study_data <- simulate_study(n_per_group, effect_size)\n    \n    # Run t-test\n    test_result <- t.test(score ~ group, data = study_data, var.equal = TRUE)\n    \n    # Store results\n    results$p_value[i] <- test_result$______\n    results$ci_lower[i] <- test_result$conf.int[1]\n    results$ci_upper[i] <- test_result$conf.int[2]\n    results$significant[i] <- test_result$p.value < alpha\n    results$effect[i] <- diff(test_result$estimate)\n  }\n  \n  return(results)\n}\n\n# Test the function\nset.seed(123)\nsim_results <- run_power_simulation(\n  n_per_group = 30,\n  effect_size = 0.5,\n  n_simulations = 10  # Using fewer for speed\n)\n\n# Show first few results\nhead(sim_results)\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_4\"}\n\nIn `simulate_study()`, the treatment group should have a mean equal to the effect_size (since control has mean 0 and SD = 1).\n\nThe p-value from a t-test is accessed with `$p.value`.\n\n```r\nsimulate_study <- function(n_per_group, effect_size) {\n  data.frame(\n    group = rep(c(\"Control\", \"Treatment\"), each = n_per_group),\n    score = c(\n      rnorm(n_per_group, mean = 0, sd = 1),\n      rnorm(n_per_group, mean = effect_size, sd = 1)\n    )\n  )\n}\n\n# In run_power_simulation:\nresults$p_value[i] <- test_result$p.value\n```\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_4\"}\n\n\n::: {.cell exercise='ex_4' solution='true'}\n```{webr}\n#| label: ex-4-solution\n#| exercise: ex_4\n#| solution: true\n# Function to simulate a single study\nsimulate_study <- function(n_per_group, effect_size) {\n  data.frame(\n    group = rep(c(\"Control\", \"Treatment\"), each = n_per_group),\n    score = c(\n      rnorm(n_per_group, mean = 0, sd = 1),\n      rnorm(n_per_group, mean = effect_size, sd = 1) #<1>\n    )\n  )\n}\n\n# Function to run many simulated studies\nrun_power_simulation <- function(\n    n_per_group,\n    effect_size,\n    n_simulations = 1000,\n    alpha = 0.05) {\n  \n  # Create storage for results\n  results <- data.frame(\n    simulation = 1:n_simulations,\n    p_value = numeric(n_simulations),\n    ci_lower = numeric(n_simulations),\n    ci_upper = numeric(n_simulations),\n    significant = logical(n_simulations),\n    effect = numeric(n_simulations)\n  )\n  \n  # Run many simulated studies\n  for (i in 1:n_simulations) {\n    # Simulate data\n    study_data <- simulate_study(n_per_group, effect_size)\n    \n    # Run t-test\n    test_result <- t.test(score ~ group, data = study_data, var.equal = TRUE)\n    \n    # Store results\n    results$p_value[i] <- test_result$p.value #<2>\n    results$ci_lower[i] <- test_result$conf.int[1]\n    results$ci_upper[i] <- test_result$conf.int[2]\n    results$significant[i] <- test_result$p.value < alpha\n    results$effect[i] <- diff(test_result$estimate)\n  }\n  \n  return(results)\n}\n\n# Test the function\nset.seed(123)\nsim_results <- run_power_simulation(\n  n_per_group = 30,\n  effect_size = 0.5,\n  n_simulations = 10  # Using fewer for speed\n)\n\n# Show first few results\nhead(sim_results)\n```\n:::\n\n1. Treatment group has mean = effect_size (Cohen's d = 0.5 when SD = 1)\n2. Extract p-value from the t-test result\n\nThis function returns a data frame with comprehensive information about each simulated study, making it easy to analyze power and other properties.\n\n:::\n\n\n::: {.cell exercise='ex_4' check='true'}\n```{webr}\n#| label: ex-4-gradethis\n#| exercise: ex_4\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n::: {#exr-simulate-power}\n## Analyze simulation results and calculate power\n:::\n\n:::: {.panel-tabset}\n## Problem\n\nNow use the simulation function to run 1000 studies and analyze the results. Calculate the statistical power and create visualizations showing the distribution of p-values and confidence intervals.\n\n\n::: {.cell exercise='ex_5' envir='sim_env' timelimit='300' persist='true'}\n```{webr}\n#| label: ex-5\n#| exercise: ex_5\n#| envir: sim_env\n#| timelimit: 300\n#| persist: true\nlibrary(ggplot2)\n\n# Run simulation\nset.seed(123)\nsim_results <- run_power_simulation(\n  n_per_group = 30,\n  effect_size = 0.5,\n  n_simulations = 1000\n)\n\n# Calculate power (proportion of p-values < 0.05)\nsimulated_power <- mean(sim_results$______ < ______)\n\ncat(\"Simulated power:\", round(simulated_power, 3), \"\\n\")\n\n# Compare to analytical power\nanalytical_power <- pwr.t.test(\n  n = 30,\n  d = 0.5,\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)$power\n\ncat(\"Analytical power:\", round(analytical_power, 3), \"\\n\")\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_5\"}\n\nThe `sim_results` data frame has a column called `p_value` with the p-value from each simulation.\n\nTo calculate power:\n- Compare each p-value to 0.05\n- Take the mean of the TRUE/FALSE values (TRUE = 1, FALSE = 0)\n\n```r\nsimulated_power <- mean(sim_results$p_value < 0.05)\n```\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_5\"}\n\n\n::: {.cell exercise='ex_5' solution='true'}\n```{webr}\n#| label: ex-5-solution\n#| exercise: ex_5\n#| solution: true\nlibrary(ggplot2)\n\n# Run simulation\nset.seed(123)\nsim_results <- run_power_simulation(\n  n_per_group = 30,\n  effect_size = 0.5,\n  n_simulations = 1000\n)\n\n# Calculate power (proportion of p-values < 0.05)\nsimulated_power <- mean(sim_results$p_value < 0.05) #<1>\n\ncat(\"Simulated power:\", round(simulated_power, 3), \"\\n\")\n\n# Compare to analytical power\nanalytical_power <- pwr.t.test(\n  n = 30,\n  d = 0.5,\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)$power\n\ncat(\"Analytical power:\", round(analytical_power, 3), \"\\n\")\n```\n:::\n\n1. Calculate proportion of p-values below 0.05 (mean of TRUE/FALSE values)\n\nThe simulated power should be very close to the analytical power (~0.47). This means about 47% of our simulated studies correctly detected the effect (had p < 0.05).\n\n:::\n\n\n::: {.cell exercise='ex_5' check='true'}\n```{webr}\n#| label: ex-5-gradethis\n#| exercise: ex_5\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n::: {#exr-simulate-ci}\n## Calculate power using confidence intervals\n:::\n\n:::: {.panel-tabset}\n## Problem\n\nAnother way to calculate power is through confidence intervals! A study detects an effect when the 95% CI excludes zero (the null hypothesis value). Calculate power by determining what proportion of confidence intervals do NOT contain zero.\n\n\n::: {.cell exercise='ex_6' persist='true' envir='sim_env'}\n```{webr}\n#| label: ex-6\n#| exercise: ex_6\n#| persist: true\n#| envir: sim_env\n\n# Calculate power from confidence intervals\n# A CI that excludes 0 means we reject the null hypothesis\nci_excludes_zero <- sim_results$ci_lower > ______ | sim_results$ci_upper < ______\npower_from_ci <- mean(ci_excludes_zero)\n\ncat(\"Power from p-values:\", round(simulated_power, 3), \"\\n\")\ncat(\"Power from CIs:     \", round(power_from_ci, 3), \"\\n\")\ncat(\"These should be identical!\\n\")\n```\n:::\n\n\n## Hints \n\n::: {.hint exercise=\"ex_6\"}\n\nA confidence interval excludes zero if:\n- The lower bound is above 0 (positive effect), OR\n- The upper bound is below 0 (negative effect)\n\nThis is equivalent to rejecting the null hypothesis (H₀: difference = 0).\n\n```r\nci_excludes_zero <- sim_results$ci_lower > 0 | sim_results$ci_upper < 0\n```\n:::\n\n## Solution\n\n::: {.solution exercise=\"ex_6\"}\n\n\n::: {.cell exercise='ex_6' solution='true'}\n```{webr}\n#| label: ex-6-solution\n#| exercise: ex_6\n#| solution: true\n\n# Calculate power from confidence intervals\n# A CI that excludes 0 means we reject the null hypothesis\nci_excludes_zero <- sim_results$ci_lower > 0 | sim_results$ci_upper < 0  #<1>\npower_from_ci <- mean(ci_excludes_zero)\n\ncat(\"Power from p-values:\", round(simulated_power, 3), \"\\n\")\ncat(\"Power from CIs:     \", round(power_from_ci, 3), \"\\n\")\ncat(\"These should be identical!\\n\")\n```\n:::\n\n1. CI excludes 0 if lower bound > 0 OR upper bound < 0\n\n**Key insight**: Power can be calculated two equivalent ways:\n- **From p-values**: Proportion where p < 0.05\n- **From confidence intervals**: Proportion where CI excludes 0\n\nThese give identical results because they're testing the same hypothesis! A 95% CI that excludes 0 corresponds exactly to p < 0.05.\n\n:::\n\n\n::: {.cell exercise='ex_6' check='true'}\n```{webr}\n#| label: ex-6-gradethis\n#| exercise: ex_6\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n::::\n\n# Summary\n\nIn this lab, you learned:\n\n1. **Power analysis basics**: The relationship between power, sample size, effect size, and significance level\n2. **Using `pwr` package**: How to calculate power or required sample size analytically\n3. **Power curves**: Visualizing how power changes with sample size\n4. **Simulation-based power**: Be basics of estimating power by simulating many studies\n",
    "supporting": [
      "lab-power-sample-size_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}