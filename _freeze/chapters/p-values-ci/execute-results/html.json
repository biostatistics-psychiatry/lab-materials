{
  "hash": "78ba070f1925b341e0cde5de8a167131",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"P-values and confidence intervals\"\n---\n\n\n\n\n# Load packages and data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\nlibrary(tidyverse)\ndf_data <- read_rds(here(\"data\", \"steps_baseline.rds\"))\n```\n:::\n\n\n\n\n# P-values\n\nProbability - defined as the long-run frequency of an event occurring - is very much used in research to get an idea of **how probable our observed data is, given some hypothesis of interest.** In probability notation $P(Data|Hypothesis)$.\n\n## Numeric variables\n\nFor instance we might have an hypothesis the the mean of LSAS-SR is 82 in the population. We can determine how probable our data would be under this hypothesis, by investigating how often we would expect to get our **observed sample mean** if this (null)hypothesis was true.\n\nFor this we would need the sampling distribution of mean LSAS-SR scores in samples of 181 people (the size, $n$, of our sample), *if the true population mean was 82.* One way to get this would be to simulate say 10 000 samples of LSAS-SR scores, from a population with a true mean of 82. To simulate this, we also need to know the spread (standard deviation) of the true population. We don't know this, but let's assume it is the same as in our sample.\n\nBelow, the function `rnorm()` is used to take a random sample of 181 values from a normal distribution with a mean of 82 and a standard deviation 16.5 (same as in out sample). We use a for loop to repeat this sampling 10 000 times and save the mean values of each sample in the vector called means.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_samples <- 1e4 # the number of samples\nsmp_size <- 181 # the size of our samples\nmeans <- rep(NA, n_samples) # an empty vector to contain our mean values\n\nfor (i in 1:n_samples) {\n  x <- rnorm(smp_size, mean = 82, sd = sd(df_data$lsas_screen))\n  means[i] <- mean(x)\n}\n\nhist(means, main = \"Simulated sampling distribution of LSAS means\")\n```\n\n::: {.cell-output-display}\n![](p-values-ci_files/figure-html/simulate-sampling-distribution-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can use this simulated sampling distribution to see how probable our *observed LSAS-SR mean* is if the (null)hypothesis that the true mean is 82 would be correct. First let plot the sampling distribution again, and show the observed LSAS-SR mean as a vertical line.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(means, main = \"Simulated sampling distribution of LSAS means\")\nabline(v = mean(df_data$lsas_screen), col = \"red\", lwd = 2, lty = 2) # vertical line showing the observed LSAS-SR mean\n```\n\n::: {.cell-output-display}\n![](p-values-ci_files/figure-html/hist-means-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can also quantify the probability by calculating, ***the proportion of times that a sample mean would be equal to or greater that our observed mean, IF the true population mean was 82*****.** This quantity is the very (in)famous **p-value.**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(means >= mean(df_data$lsas_screen)) # proportion of simulated means that are larger than our observed mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0138\n```\n\n\n:::\n:::\n\n\n\n\nIf we find this simulation exercise a bit tedious, we could also use theoretical distributions for the sample means to calculate our p-value. The **t-distribution** can be used to estimate the spread to the sample means *when the population variance is unknown and the sample variance is used to approximate it*. It is very similar to the normal distribution, but has heavier tails that accounts for the uncertainty produced by using the sample variance instead of the true population variance when estimating the standard error of the sampling distribution. However, when the sample size increase, the t-distribution will come closer and closer to a normal distribution (also known as a z-distribution when standardized to have mean=0 and sd=1).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up the plot range\nx_range <- seq(-4, 4, length = 500)\n\n# Plot standard normal distribution\nplot(x_range, dnorm(x_range),\n  type = \"l\", lwd = 2, col = \"black\",\n  ylab = \"Density\", xlab = \"x\", main = \"t-Distribution vs Normal Distribution\"\n)\n\n# Add t-distributions with different degrees of freedom\nlines(x_range, dt(x_range, df = 1), col = \"red\", lwd = 2, lty = 2)\nlines(x_range, dt(x_range, df = 5), col = \"blue\", lwd = 2, lty = 3)\nlines(x_range, dt(x_range, df = 15), col = \"darkgreen\", lwd = 2, lty = 4)\nlines(x_range, dt(x_range, df = 30), col = \"purple\", lwd = 2, lty = 5)\n\n# Add a legend\nlegend(\"topright\",\n  legend = c(\"Normal (Z)\", \"t (df=1)\", \"t (df=5)\", \"t (df=15)\", \"t (df=30)\"),\n  col = c(\"black\", \"red\", \"blue\", \"darkgreen\", \"purple\"),\n  lwd = 2, lty = 1:5, bty = \"n\"\n)\n```\n\n::: {.cell-output-display}\n![](p-values-ci_files/figure-html/t-dist-plot-1.png){width=672}\n:::\n:::\n\n\n\n\nThe probability of getting a a sample mean that is greater or equal to our observed mean, given some true population mean, $\\mu$, can be calculated by transforming our observed mean to a **t-value** and compare it to the **t-distribution**.\n\nThe t-value of our mean $\\bar{x}$ under the null hypothesis that the population mean is $\\mu$, is given by the formula:\n\n$$\nt = \\frac{\\bar{x} - \\mu}{SE}\n$$\n\nReplacing these Greek letters with our actual values $\\bar{x} = 84.75$, $\\mu = 82$, and $SE=1.22$, we get:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse <- sd(df_data$lsas_screen) / sqrt(nrow(df_data))\nx_bar <- mean(df_data$lsas_screen)\nt_value <- (x_bar - 82) / se\nt_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.24774\n```\n\n\n:::\n:::\n\n\n\n\nNow let's find the probability of getting a t-value larger or equal to this - **our one-sided p-value!** For this we use the `pt()` function, that provides the cumulative probability up until a given t-value. 1 minus this cumulative probability gives the probability of values equal or above the given t-value.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pt(t_value, df = 180)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01290324\n```\n\n\n:::\n:::\n\n\n\n\n::: callout-note\n## z-values and t-values\n\nWhen the sample size increases, the t-distribution approaches the z-distribution and these estimates become very similar. As a general rule of thumb, it is fine to use z-values rather than t-values for sample sizes larger than 200.\n:::\n\nWe could also get a very similar p-value from the z-distribution (although we would assume we know the population variance for out calculation of the standard error). The `pnorm()` function gives the cumulative probability up to some specific value for the normal distribution, which when the mean is 0 and the SD is 1 is also called the z-distribution.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pnorm(t_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01229639\n```\n\n\n:::\n:::\n\n\n\n\nSinnce our sample is quite large, the p-value from the t-distribution and the z-distribution are very similar. Also very similar to our simulated p-value above! More conveniently, of course, we could get this p-value using the `t.test()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(df_data$lsas_screen, mu = 82, alternative = \"greater\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  df_data$lsas_screen\nt = 2.2477, df = 180, p-value = 0.0129\nalternative hypothesis: true mean is greater than 82\n95 percent confidence interval:\n 82.72756      Inf\nsample estimates:\nmean of x \n 84.75138 \n```\n\n\n:::\n:::\n\n\n\n\n::: callout-note\n## One-sided and two-sided p-values\n\nWhat we have now calculated in three different ways is the **one-sided** p-value. It's one-sided since we only looked at the probability to *get data equal to or greater* than our observed data, given that the null-hypothesis was true.\n\nIf we wanted to see the probability of getting data equal or greater than our observed data OR equal or less than out observed data under the null-hypothesis, we would want a **two-sided** **p-value.** Since the sampling distribution is symmetrical, we could get this by multiplying of one-sided p-value by 2.\n:::\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](p-values-ci_files/figure-html/p-value-plot-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](p-values-ci_files/figure-html/p-value-plot-2.png){width=672}\n:::\n:::\n\n\n\n\nCode for two-sided p-values\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# manual code\nse <- sd(df_data$lsas_screen) / sqrt(nrow(df_data))\nx_bar <- mean(df_data$lsas_screen)\nt_value <- (x_bar - 82) / se\n(1 - pt(t_value, df = 180)) * 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02580648\n```\n\n\n:::\n\n```{.r .cell-code}\n# or using the t-test function\nt.test(df_data$lsas_screen, mu = 82, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  df_data$lsas_screen\nt = 2.2477, df = 180, p-value = 0.02581\nalternative hypothesis: true mean is not equal to 82\n95 percent confidence interval:\n 82.33602 87.16675\nsample estimates:\nmean of x \n 84.75138 \n```\n\n\n:::\n:::\n\n\n\n\n## Proportions\n\nThis same logic applies to proportions, but we can't use the `t.test()` function anymore. Instead we can use the `prop.test()` function.\n\nWe have no categorical variables in the STePs data, so let's simulate a gender variable:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulating a gender variable\nn <- nrow(df_data)\ndf_data$gender <- rbinom(n, 1, 0.7)\ndf_data$gender <- ifelse(df_data$gender == 1, \"Woman\", \"Man\")\n```\n:::\n\n\n\n\nWe can the use the `prop.test()` function to get a one-sided or two sided p-value, given some assumed population proportion, say that 32% are men.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#one-sided p-value\nprop.test(table(df_data$gender),\n          p=0.32,\n          alternative = \"less\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t1-sample proportions test with continuity correction\n\ndata:  table(df_data$gender), null probability 0.32\nX-squared = 0.051196, df = 1, p-value = 0.4105\nalternative hypothesis: true p is less than 0.32\n95 percent confidence interval:\n 0.0000000 0.3712229\nsample estimates:\n        p \n0.3093923 \n```\n\n\n:::\n\n```{.r .cell-code}\n#two-sided p-value\n#one-sided p-value\nprop.test(table(df_data$gender),\n          p=0.32,\n          alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t1-sample proportions test with continuity correction\n\ndata:  table(df_data$gender), null probability 0.32\nX-squared = 0.051196, df = 1, p-value = 0.821\nalternative hypothesis: true p is not equal to 0.32\n95 percent confidence interval:\n 0.2440553 0.3829729\nsample estimates:\n        p \n0.3093923 \n```\n\n\n:::\n:::\n\n\n\n\n# Confidence intervals\n\nUsing the standard error, we can also calculate the confidence interval, defined as **an interval that, if computed on a repeated set of samples, would contain the true population statistic 95% of the times.**\n\n## Numeric variables\n\nWhen the sample standard deviation, $s$, is used, we get the confidence intervals by taking the observed mean and adding or subtracting the *t-value* of the desired percentiles of the sampling distribution (indicated by the asterix) times the *standard error,* $\\frac{s}{\\sqrt{n}}$\n\n$$ \\text{CI} = \\bar{x} \\pm t^*\\ \\frac{s}{\\sqrt{n}}$$\n\nIf we knew the *standard deviation of the population,* we could substitute the sample standard deviation, $s$ for the population standard deviation, $\\sigma$, and use *z*-values instead of *t-values.* For 95% confidence intervals, the z-value is 1.96.\n\n$$\n\\text{CI} = \\bar{x} \\pm z^*\\frac{\\sigma}{\\sqrt{n}}\n$$\n\nNow let's use these formulas to calculate the confidence interval of the mean of LSAS-SR\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_value <- qt(1 - 0.025, 180) # the t-value for a 95% confidence interval with 180 degrees of freedom\n\nse <- sd(df_data$lsas_screen) / sqrt(nrow(df_data)) # standard error of LSAS-SR\n\nucl <- mean(df_data$lsas_screen) + t_value * se # the upper confidence limit\nlcl <- mean(df_data$lsas_screen) - t_value * se # the lower confidence limit\n\nprint(c(lcl, ucl))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 82.33602 87.16675\n```\n\n\n:::\n:::\n\n\n\n\nWe can also use the `t.test()` function to get this interval\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(df_data$lsas_screen, conf.level = 0.95) # For a 95% CI\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  df_data$lsas_screen\nt = 69.238, df = 180, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 82.33602 87.16675\nsample estimates:\nmean of x \n 84.75138 \n```\n\n\n:::\n:::\n\n\n\n\nLet's also see what happens if we use z-values (for 95% confidence intervals, the z-value is approx 1.96)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse <- sd(df_data$lsas_screen) / sqrt(nrow(df_data)) # standard error of LSAS-SR\n\nucl <- mean(df_data$lsas_screen) + 1.96 * se\nlcl <- mean(df_data$lsas_screen) - 1.96 * se\n\nprint(c(lcl, ucl))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 82.35221 87.15055\n```\n\n\n:::\n:::\n\n\n\n\n## Proportions\n\nThe logic of confidence intervals are the same for proportions, we take our observed value $\\pm$ z times the standard error\n\nFor a proportion, the confidence intervals therefore becomes:\n\n$$ \\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} $$\n\n::: {.callout-tip collapse=\"true\"}\n## Confidence intervals for proportions\n\nThis confidence intervals for proportion, known as Wald confidence intervals, is easy to compute. However, since it uses the sample proportion to estimate the population proportion, they can be erratic, especially when $\\hat{p}$ approach 0 or 1. We therefore recommend using more advanced confidence intervals, calculated by statistical software, for instance using the function `prop.test()`.\n:::\n\nIf we want to get a confidence interval for a proportion in R, we can get this using the `prop.test()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.test(table(df_data$gender))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t1-sample proportions test with continuity correction\n\ndata:  table(df_data$gender), null probability 0.5\nX-squared = 25.547, df = 1, p-value = 4.317e-07\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.2440553 0.3829729\nsample estimates:\n        p \n0.3093923 \n```\n\n\n:::\n:::\n",
    "supporting": [
      "p-values-ci_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}