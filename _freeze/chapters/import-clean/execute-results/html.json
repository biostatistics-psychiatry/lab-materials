{
  "hash": "aaa7fa0ea552176eb21397985e087f01",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Import and clean data\"\n---\n\n\n\n\nIn this chapter, we will:\n\n- Introduce the datasets we will be using throughout the course\n- Import data into R\n- Perform basic cleaning of the data\n\n# Introduction to the dataset\n\n::: callout-note\nThis datasets have the common .csv file format, which is very popular. If you need to import other file formats, such as .xlsx (Excel) or .sav (SPSS), you can use the `readxl` and `haven` packages, respectively.\n:::\n\n## STePS-study\n\nThis is a dataset from the STePS study, which is a RCT comparing guided and unguided internet-delivered psychodynamic therapy for social anxiety disorder. The study [is published online](https://www.nature.com/articles/s44184-024-00063-0).\n\nIn true open science fashion, the data is openly available online from the [Open Science Framework](https://osf.io/cxmte/files/621b1b8c-392f-4c40-97f4-bdf60e133a4c?view_only=). \n\n# Load packages\n\nWe will be using the *tidyverse* package quite a lot in this course. *Tidyverse* is a collection of useful packages for data manipulation and visualization, such as `dplyr` and `ggplot2`. We will also use the *here* package, which helps us manage file paths in a simple way. Finally, the *janitor* package has a great function for cleaning column names.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n```\n:::\n\n\n\n\nIf you are using `R` for the first time, you have to run the following code in the **console** to install the packages (one time only!). You can then load them using the `library()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(tidyverse)) install.packages(\"tidyverse\")\nif (!require(here)) install.packages(\"here\")\n```\n:::\n\n\n\n\n::: {.callout-tip}\n## R packages\n\nThere is a rich ecosystem of *packages* for R, which add functionality to the base R language. You can find specialised packages for many different tasks. It's important to keep in mind, however, that these are developed open source, and it is good practice to always read the documentation so that you understand how to use the package correctly.\n\n:::\n\n# Importing data into R\n\nLet's start working with the *STePS* dataset. We use the `read_csv()` function, along with the `here()` function, to import the data. Within the `here()` function, we first specify the folder, then the filename. This is helpful for keeping the file paths clean, and makes it easier to share your code with others since the file paths are relative to the project folder.\n\nWe also check the number of rows and columns in the dataset after importing it.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_rawdata <- read_csv2(here(\"data\", \"steps_raw.csv\"))\n\nrow_check <- nrow(df_rawdata) # 181\ncol_check <- ncol(df_rawdata) # 37\n```\n:::\n\n\n\n\n## Check data structure\n\nAfter importing the data, we can check the structure of the dataset using the `glimpse()` function. This function provides a quick overview of the dataset, including the number of rows and columns, as well as the data types of each column. Does it look as expected?\n\nYour object `df_rawdata` should contain 181 rows and 37 columns. We can see that the first column is named *ID*, which is the unique identifier for each participant. The second column is named *Group*, which indicates the group assignment: unguided treatment, guided treatment, or waitlist. The rest seem to be various questionnaires and scales.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(df_rawdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 181\nColumns: 37\n$ ID               <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ Group            <dbl> 2, 1, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 1, 1, 2, 0,…\n$ `LSAS Screening` <dbl> 63, 71, 98, 63, 74, 81, 67, 76, 88, 73, 86, 78, 97, 7…\n$ GAD_screen       <dbl> 7, 17, 18, 8, 14, 11, 5, 8, 14, 5, 15, 16, 17, 13, 10…\n$ `PHQ-9 screen`   <dbl> 6, 13, 19, 4, 18, 8, 9, 8, 14, 3, 5, 11, 12, 18, 10, …\n$ BBQ_screen       <dbl> 60, 66, 4, 50, 22, 23, 47, 52, 31, 46, 67, 24, 57, 40…\n$ SCS_screen       <dbl> 25, 16, 22, 35, 29, 30, 20, 34, 21, 26, 35, 21, 32, 3…\n$ DMRSODF_screen   <dbl> 49178, 50727, 45074, 5381, 48444, 50899, 46923, 41428…\n$ `DERS-16_screen` <dbl> 44, 73, 65, 45, 46, 49, 57, 38, 67, 45, 55, 56, 71, 3…\n$ `PID-5_screen`   <dbl> 25, 20, 48, 17, 24, 20, 24, 26, 39, 23, 24, 26, 23, 1…\n$ LSAS_V1          <chr> \"72\", \"missing\", \"81\", \"44\", \"39\", \"65\", \"68\", \"69\", …\n$ LSAS_V2          <chr> \"64\", \"missing\", \"89\", \"33\", \"115\", \"64\", NA, \"70\", \"…\n$ LSAS_V3          <chr> \"72\", \"missing\", \"73\", \"36\", \"missing\", \"63\", NA, \"71…\n$ LSAS_V4          <chr> \"61\", \"missing\", \"94\", \"44\", \"missing\", \"60\", NA, \"51…\n$ LSAS_V5          <chr> \"61\", NA, \"93\", \"21\", \"missing\", \"55\", NA, \"55\", NA, …\n$ LSAS_V6          <chr> \"46\", NA, \"88\", \"20\", \"missing\", \"46\", NA, \"56\", \"93\"…\n$ LSAS_V7          <dbl> 55, NA, NA, 18, NA, 45, NA, 64, NA, 54, 101, NA, 89, …\n$ LSAS_V8          <dbl> 49, NA, NA, 17, NA, 44, NA, 52, NA, 61, 84, NA, 89, N…\n$ LSAS_POST        <dbl> 50, NA, 77, 22, NA, 52, 75, 45, 79, 64, 80, 89, 83, 4…\n$ GAD_POST         <dbl> 4, NA, 19, 6, NA, 9, 4, 3, 10, 7, 15, 7, 11, 11, 11, …\n$ `PHQ-9_POST`     <dbl> 3, NA, 22, 4, NA, 6, 11, 2, 14, 4, 8, 7, 8, 8, 13, 4,…\n$ BBQ_POST         <chr> \"76\", NA, \"68\", \"57\", \"missing\", \"14\", \"46\", \"70\", \"3…\n$ SCS_POST         <dbl> 34, NA, 34, 34, NA, 30, 19, 34, 23, 23, 31, 37, 34, 3…\n$ DMRSODF_POST     <dbl> 50776, NA, 42809, 52069, NA, 51758, 49, 50235, 47978,…\n$ `DERS-16_POST`   <dbl> 36, NA, 78, 38, NA, 54, 61, 26, 56, 51, 52, 25, 37, 3…\n$ LSAS_FU6         <dbl> 33, NA, NA, 14, 6, 60, 64, 49, NA, 45, 85, 74, NA, 58…\n$ GAD_FU6          <dbl> 0, NA, NA, 0, NA, 14, 6, 4, NA, 5, 16, NA, NA, 11, 8,…\n$ PHQ9_FU6         <dbl> 3, NA, NA, 2, NA, 6, 8, 3, NA, 6, 22, NA, NA, 6, 5, 1…\n$ BBQ_FU6          <dbl> 77, NA, NA, 68, NA, 9, 56, 64, NA, 48, 36, NA, NA, 39…\n$ SCS_FU6          <chr> \"28\", NA, NA, \"41\", \"missing\", \"24\", \"29\", \"33\", \"mis…\n$ DERS_FU6         <dbl> 35, NA, NA, 36, NA, 72, 61, 26, NA, 37, 67, NA, NA, 3…\n$ LSAS_FU12        <dbl> 27, NA, NA, 16, 39, 75, 66, 43, NA, 51, 79, NA, NA, 5…\n$ GAD_FU12         <dbl> 5, NA, NA, 0, 11, 7, 6, 4, NA, 4, 14, NA, NA, 8, 19, …\n$ `PHQ-9_FU12`     <dbl> 5, NA, NA, 2, 19, 9, 14, 3, NA, 5, 15, NA, NA, 8, 18,…\n$ BBQ_FU12         <dbl> 76, NA, NA, 62, 12, 22, 52, 54, NA, 47, 25, NA, NA, 3…\n$ SCS_FU12         <dbl> 38, NA, NA, 40, 28, 33, 26, 34, NA, 21, 30, NA, NA, 3…\n$ DERS16_FU12      <dbl> 35, NA, NA, 32, 46, 65, 42, 27, NA, 53, 52, NA, NA, 3…\n```\n\n\n:::\n:::\n\n\n\n\nOther options for checking the basic structure of the data include `head()`, `names()`, `ncol()`, and `nrow()`.\n\n- `head(df_rawdata)` shows the first few rows of the dataset.\n- `names(df_rawdata)` shows the names of the columns.\n- `ncol(df_rawdata)` shows the number of columns in the dataset.\n- `nrow(df_rawdata)` shows the number of rows in the dataset.\n\n## Types of data\n\nIt's good practice to check and verify the type of data in each column after importing the data. For example, if you have a variable that should be numeric, but is instead character, you need to fix this before you can do any analyses. You will learn more about manipulating data types in the [Tidy data manipulation](tidy-data-manipulation.qmd) chapter.\n\nThe most common types of columns you will work with are:\n\n- `chr`: character strings\n- `int`: integers\n- `dbl`: numeric values\n- `lgl`: logical (TRUE/FALSE)\n- `fct`: factors\n- `date`: dates\n\nOur dataset is fairly clean, but there are problems with some variables. You can see from the `glimpse()` call above that some variables for LSAS and other questionnaires are coded as `<chr>` even though they should only have numbers. We will address these issues below.\n\n# Data cleaning\n\nFrom the output above, we can see some potential issues with the raw data:\n\n- Some column names contain spaces and other problematic characters (such as `-`).\n- There are missing values in several columns.\n- The measurement points are not consistent.\n- The data types of some columns are not as expected (e.g., character instead of numeric).\n\nLet's get started with cleaning the data. Before we proceed, we will create a copy of the raw data and leave `df_rawdata` unchanged. This is a good practice to avoid losing the original data and to keep track of the changes we make.\n\n::: callout-important\nMake a habit of keeping the raw data you import from data collection platforms (e.g., BASS, REDCap) unchanged. This way, your life will be easier when you need to do new exports or updates. You can always go back to the original data if needed.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_data <- df_rawdata\n```\n:::\n\n\n\n\n## Clean column names\n\nWe will use the `clean_names()` function from the *janitor* package to clean the column names. This function replaces spaces and other problematic characters with underscores, and converts all names to lowercase. This makes it easier to work with the data later on.\n\nWhat's wrong with these column names? And what is the difference after `clean_names()`?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(df_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"ID\"             \"Group\"          \"LSAS Screening\" \"GAD_screen\"    \n [5] \"PHQ-9 screen\"   \"BBQ_screen\"     \"SCS_screen\"     \"DMRSODF_screen\"\n [9] \"DERS-16_screen\" \"PID-5_screen\"   \"LSAS_V1\"        \"LSAS_V2\"       \n[13] \"LSAS_V3\"        \"LSAS_V4\"        \"LSAS_V5\"        \"LSAS_V6\"       \n[17] \"LSAS_V7\"        \"LSAS_V8\"        \"LSAS_POST\"      \"GAD_POST\"      \n[21] \"PHQ-9_POST\"     \"BBQ_POST\"       \"SCS_POST\"       \"DMRSODF_POST\"  \n[25] \"DERS-16_POST\"   \"LSAS_FU6\"       \"GAD_FU6\"        \"PHQ9_FU6\"      \n[29] \"BBQ_FU6\"        \"SCS_FU6\"        \"DERS_FU6\"       \"LSAS_FU12\"     \n[33] \"GAD_FU12\"       \"PHQ-9_FU12\"     \"BBQ_FU12\"       \"SCS_FU12\"      \n[37] \"DERS16_FU12\"   \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_data <- df_data |>\n  clean_names()\n```\n:::\n\n\n\n\nWe have sorted some of the problems, but we still have inconsistent names for time-points (*screening* and *screen*), and some questionnaires seems to have gotten inconsistent names as well (*ders_16*, *ders16*, and *ders*).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_data <- df_data |>\n  rename_with(~ .x |>\n    str_replace_all(\"screening\", \"screen\") |>\n    str_replace_all(\"ders_16|ders16\", \"ders\") |>\n    str_replace_all(\"phq_9\", \"phq9\"))\n```\n:::\n\n\n\n\n::: {.callout-tip}\n## This is rarely a linear process\n\nThis type of data cleaning is often a result of going back and forth between running code and checking the results. Sometimes you will come all the way to the analyses before finding that DERS-16 is missing a time-point! This is why it's helpful to design your project in a way that allows you to easily go back and forth between steps.\n:::\n\n## Ensure missing values are coded as NA\n\nIf we are lucky, all the missing values are already coded as `NA` and R will recognize them as missing. More often, however, is that the missing values are coded as `\"\"`, `-99`, or other values. This can cause problems later, so we need to ensure that all missing values are coded as `NA`.\n\nSometimes, weird labels for missing values is also the reason why some columns are not recognized as numeric.\n\nLet's check the data structure again. It looks like some columns that should be numeric are instead `<chr>`, which means they are character strings.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(df_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 181\nColumns: 37\n$ id             <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ group          <dbl> 2, 1, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 1, 1, 2, 0, 1…\n$ lsas_screen    <dbl> 63, 71, 98, 63, 74, 81, 67, 76, 88, 73, 86, 78, 97, 72,…\n$ gad_screen     <dbl> 7, 17, 18, 8, 14, 11, 5, 8, 14, 5, 15, 16, 17, 13, 10, …\n$ phq9_screen    <dbl> 6, 13, 19, 4, 18, 8, 9, 8, 14, 3, 5, 11, 12, 18, 10, 4,…\n$ bbq_screen     <dbl> 60, 66, 4, 50, 22, 23, 47, 52, 31, 46, 67, 24, 57, 40, …\n$ scs_screen     <dbl> 25, 16, 22, 35, 29, 30, 20, 34, 21, 26, 35, 21, 32, 33,…\n$ dmrsodf_screen <dbl> 49178, 50727, 45074, 5381, 48444, 50899, 46923, 41428, …\n$ ders_screen    <dbl> 44, 73, 65, 45, 46, 49, 57, 38, 67, 45, 55, 56, 71, 36,…\n$ pid_5_screen   <dbl> 25, 20, 48, 17, 24, 20, 24, 26, 39, 23, 24, 26, 23, 15,…\n$ lsas_v1        <chr> \"72\", \"missing\", \"81\", \"44\", \"39\", \"65\", \"68\", \"69\", NA…\n$ lsas_v2        <chr> \"64\", \"missing\", \"89\", \"33\", \"115\", \"64\", NA, \"70\", \"97…\n$ lsas_v3        <chr> \"72\", \"missing\", \"73\", \"36\", \"missing\", \"63\", NA, \"71\",…\n$ lsas_v4        <chr> \"61\", \"missing\", \"94\", \"44\", \"missing\", \"60\", NA, \"51\",…\n$ lsas_v5        <chr> \"61\", NA, \"93\", \"21\", \"missing\", \"55\", NA, \"55\", NA, \"6…\n$ lsas_v6        <chr> \"46\", NA, \"88\", \"20\", \"missing\", \"46\", NA, \"56\", \"93\", …\n$ lsas_v7        <dbl> 55, NA, NA, 18, NA, 45, NA, 64, NA, 54, 101, NA, 89, 43…\n$ lsas_v8        <dbl> 49, NA, NA, 17, NA, 44, NA, 52, NA, 61, 84, NA, 89, NA,…\n$ lsas_post      <dbl> 50, NA, 77, 22, NA, 52, 75, 45, 79, 64, 80, 89, 83, 45,…\n$ gad_post       <dbl> 4, NA, 19, 6, NA, 9, 4, 3, 10, 7, 15, 7, 11, 11, 11, 1,…\n$ phq9_post      <dbl> 3, NA, 22, 4, NA, 6, 11, 2, 14, 4, 8, 7, 8, 8, 13, 4, 1…\n$ bbq_post       <chr> \"76\", NA, \"68\", \"57\", \"missing\", \"14\", \"46\", \"70\", \"36\"…\n$ scs_post       <dbl> 34, NA, 34, 34, NA, 30, 19, 34, 23, 23, 31, 37, 34, 34,…\n$ dmrsodf_post   <dbl> 50776, NA, 42809, 52069, NA, 51758, 49, 50235, 47978, 4…\n$ ders_post      <dbl> 36, NA, 78, 38, NA, 54, 61, 26, 56, 51, 52, 25, 37, 33,…\n$ lsas_fu6       <dbl> 33, NA, NA, 14, 6, 60, 64, 49, NA, 45, 85, 74, NA, 58, …\n$ gad_fu6        <dbl> 0, NA, NA, 0, NA, 14, 6, 4, NA, 5, 16, NA, NA, 11, 8, 8…\n$ phq9_fu6       <dbl> 3, NA, NA, 2, NA, 6, 8, 3, NA, 6, 22, NA, NA, 6, 5, 12,…\n$ bbq_fu6        <dbl> 77, NA, NA, 68, NA, 9, 56, 64, NA, 48, 36, NA, NA, 39, …\n$ scs_fu6        <chr> \"28\", NA, NA, \"41\", \"missing\", \"24\", \"29\", \"33\", \"missi…\n$ ders_fu6       <dbl> 35, NA, NA, 36, NA, 72, 61, 26, NA, 37, 67, NA, NA, 36,…\n$ lsas_fu12      <dbl> 27, NA, NA, 16, 39, 75, 66, 43, NA, 51, 79, NA, NA, 55,…\n$ gad_fu12       <dbl> 5, NA, NA, 0, 11, 7, 6, 4, NA, 4, 14, NA, NA, 8, 19, 12…\n$ phq9_fu12      <dbl> 5, NA, NA, 2, 19, 9, 14, 3, NA, 5, 15, NA, NA, 8, 18, 3…\n$ bbq_fu12       <dbl> 76, NA, NA, 62, 12, 22, 52, 54, NA, 47, 25, NA, NA, 33,…\n$ scs_fu12       <dbl> 38, NA, NA, 40, 28, 33, 26, 34, NA, 21, 30, NA, NA, 32,…\n$ ders_fu12      <dbl> 35, NA, NA, 32, 46, 65, 42, 27, NA, 53, 52, NA, NA, 36,…\n```\n\n\n:::\n:::\n\n\n\n\nLet's fix this by replacing the problematic values with `NA`. We will use the `mutate()` and `across()` functions from the *dplyr* package to apply the `na_if()` function to all character columns. This will replace any occurrence of \"missing\" with `NA`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_data <- df_data |>\n  mutate(across(where(is.character), ~ na_if(., \"missing\")))\n```\n:::\n\n\n\n\n## Fix column types\n\nThe NA values are now correctly coded, but we still have some columns that are not numeric despite only including numbers. We can use the `mutate()` function again to convert the columns to the correct data type. In this step, we also ensure that the `id` and `group` columns are factors.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# which columns should be numeric?\nnum_cols <- c(\"lsas\", \"gad\", \"phq9\", \"bbq\", \"scs\", \"dmrsodf\", \"ders\", \"pid_5\")\n\ndf_data <- df_data |>\n  mutate(\n    across(starts_with(num_cols), as.numeric),\n    id = factor(id),\n    group = factor(group)\n  )\n```\n:::\n\n\n\n\n# Create a treatment indicator variable\n\nOur *group* variable is coded as 0, 1, and 2. This is not very informative, and we run the risk of misinterpreting the results if we don't have clear labels for the three groups. Let's create a new variable `trt` with better labels.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_data <- df_data |>\n  mutate(\n    trt = factor(\n      group,\n      levels = c(0, 1, 2),\n      labels = c(\"waitlist\", \"self-guided\", \"therapist-guided\")\n    )\n  )\n```\n:::\n\n\n\n\n# Save the cleaned data\n\nNow that we have cleaned the data, we can save it as a new CSV file. We will use the `write_csv()` function from the *readr* package to do this. The cleaned data will be saved in the `data` folder with the name `steps_clean.csv`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(df_data, here(\"data\", \"steps_clean.csv\"))\n```\n:::\n\n\n\n\n::: {.callout-tip}\n## Saving data\n\nWhen working with data in your research projects, it's a good idea to save your data in formats that can be reused later. In this course we are using an open dataset, but for your own projects you may want to save your data on KI server or another secure location.\n\nTry to keep your file names readable and understandable for both machines and humans.\n\n- Avoid spaces or special characters in file names\n- Use underscores `_` or hyphens `-` to separate words\n- Use lowercase letters\n- Use date stamps when relevant (e.g., `bass_export_2024_01_15.csv`)\n- Use descriptive names (e.g., `steps_baseline.csv`)\n- Be consistent in naming\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}