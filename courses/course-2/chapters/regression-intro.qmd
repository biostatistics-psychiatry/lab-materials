---
title: "Chapter 1: Introduction to Linear and Quantile Regression in R"
format: html
editor: visual
toc: true
toc-depth: 3
---

# Introduction

This chapter introduces the simplest possible regression model:\
a **model with no predictors**, also known as an **intercept-only** model.

Even though the model is simple, it allows us to illustrate all core components of regression:

-   how R fits regression models
-   how to extract model estimates
-   how regression objects are structured
-   how to get model predictions using `marginaleffects`
-   how to visualize regression results
-   how to compute confidence intervals and standard errors

# 1. Packages and Functions

In this lab we use four core packages.

```{r, message=FALSE, warning=FALSE}
library(tidyverse)        # Data wrangling and plotting
library(broom)            # Converting model objects into tidy tables
library(quantreg)         # Quantile regression (rq())
library(marginaleffects)  # Predictions and uncertainty estimates
library(here)
```

**Why these packages?**

-   `lm()` fits linear regression models.

-   `rq()` fits quantile regression models.

-   `broom` helps inspect regression objects in tidy tables.

-   `marginaleffects` provides **model-based predictions + standard errors + confidence intervals**, even for quantile regression.

-   `ggplot2` (part of tidyverse) allows flexible, reproducible visualizations.

## Load the data

We'll again use the dataset from the STePS study, which is a RCT comparing guided and unguided internet-delivered psychodynamic therapy for social anxiety disorder. The study [is published online](https://www.nature.com/articles/s44184-024-00063-0).

```{r, message=FALSE, warning=FALSE}
df <- read.csv(here("data", "steps_clean.csv"))

# we also rename the "group" variable, otherwise it causes issues with the marginal effects pakage
df <- df %>% rename(grp = group)
```

We assign this dataset to an object called df.

# 2. Syntax of Intercept-Only Models in R

An intercept-only model estimates a **single number**:

-   the **mean** for linear regression

-   a **quantile** (e.g., median) for quantile regression

There are *no predictors*, so the model formula is simply:

```{r, echo=FALSE}
lsas_post ~ 1
```

This is R syntax for the formula:

$$E(LSAS_{post}) = \beta_0$$

Where *E* refers to the expected value (mean or median)

## 2.1 Linear regression (mean)

So let's fit an intercept-only model for the score of the LSAS scale at post-treatment in the STePS study. First we use the `lm()`function to fit the regression model. To be able to easily access the model, we save in in an object calles `mod_lm.` Using the `summary()` function on this regression object gives the most essential information on the model.

```{r}
mod_lm <- lm(lsas_post ~ 1, data = df)
summary(mod_lm)
```

Here, the coefficient represents the **estimated mean** of the outcome. As this is a intercept-only model (i.e. no predictors) the estimated mean is identical to the actual mean:

```{r}
mean(df$lsas_post, na.rm=TRUE)
```

## 2.2 Quantile regression (median)

Here we do the same thing as above, but use the `rq()` function to fit a quantile regression model, and the `summary()` function to get the most essential information.

```{r}
mod_rq <- rq(lsas_post ~ 1, tau = 0.5, data = df)
summary(mod_rq)
```

The parameter `tau` sets the quantile:

-   `tau = 0.5` → median

-   `tau = 0.1` → 10th percentile

-   `tau = 0.9` → 90th percentile

The value of the intercept is the **estimated quantile** of the outcome. Again since this is an intercept-only model, the value is the same as the median in the sample

```{r}
median(df$lsas_post, na.rm=T)
```

# 3. Parts of the Regression Object

Model objects contain all components needed for inference. While the `summary()` function gives an overall summary of the model, there are several other functions to retrieve specific information from the regression objects.

## 3.1 Components of the linear model

You can use different functions to access information from the regression R obejct.

```{r}
names(mod_lm) # gives the names of the different parts of the regression object
coef(mod_lm) # returns the coefficients from the object 
head(fitted(mod_lm)) # gets the predicted values for each individual
head(residuals(mod_lm)) # returns the residuals (actual value - predicted value)
```

Key parts:

-   **coefficients** — the estimated mean

-   **fitted values** — all equal to the estimated mean in the intercept-only model

-   **residuals** — deviation of each observation from the fitted value (i.e. value predicted by the model)

You can also access specific information from the regression object by using the `$` operator.

```{r}
mod_lm$coefficients # the coefficients of the model (right now only the intercept)
head(mod_lm$residuals) # the residuals (actual value - predicted value)
```

## 3.2 Components of the quantile regression model

```{r}
names(mod_rq)
coef(mod_rq)
```

Quantile regression objects have similar structure, but contain quantile-specific information.

Again you can get information directly from the regression R object:

```{r}
mod_rq$coefficients # the coefficient
head(mod_rq$residuals) # the residuals (actual value - predicted value)
head(df$lsas_post)
```

# 4. Getting Estimates from the Model Using `marginaleffects`

The `marginaleffects` package lets us extract:

-   predicted values

-   standard errors

-   confidence intervals

For intercept-only models, predictions are **constant**, as we have no predictors that can vary between subjects predicted values are the same across all subjects.

## 4.1 Average prediction (linear regression)

```{r}
avg_predictions(mod_lm)
```

This returns:

-   estimated mean

-   standard error

-   confidence interval

## 4.2 Individual predictions

```{r}
predictions(mod_lm) %>% head()
```

These are equal for every observation because there are no predictors.

## 4.3 Median prediction (quantile regression)

```{r}
avg_predictions(mod_rq)
```

This returns the estimated median (or any other quantile selected).

# 5. Visualizing the Model with `ggplot2`

The visualization step shows how the estimated mean or median aligns with the empirical distribution.

## 5.1 Histogram with the estimated mean (linear model)

```{r, warning=FALSE}
mean_est <- coef(mod_lm) # save the estimated mean from the linear model

# plot the mean over a histogram of the observed values
ggplot(df, aes(lsas_post)) +
geom_histogram(bins = 25, color = "white") +
geom_vline(xintercept = mean_est, linewidth = 1.2) +
labs(title = "Estimated Mean (Intercept-Only Linear Model)",
x = "y", y = "Frequency")
```

## 5.2 Estimated mean with confidence interval (linear model)

```{r}
#get the estimated values from the linear prediction model
ap <- avg_predictions(mod_lm)

# save the as a tibble object for plotting
df_plot <- tibble(
  mean_est = ap$estimate[1],
  lcl = ap$conf.low[1],
  ucl = ap$conf.high[1]
)

# use ggplot to create a plot
ggplot(df_plot, aes(y = 1, x = mean_est)) +
  geom_point(size = 3) +
  geom_errorbar(aes(xmin = lcl, xmax = ucl), width = 0.1, linewidth = 1) + # add confidence interval 
  scale_y_continuous(breaks = NULL) + # remove the y-axis scale
  scale_x_continuous(limits = c(50, 90)) +   # # set x-axis range
  labs( # set labels 
    y = "",
    x = "Estimated Mean (95% CI)"
  ) +
  theme_minimal()
```

## 5.3 Histogram with median (quantile regression)

```{r}
med_est <- coef(mod_rq)

ggplot(df, aes(lsas_post)) +
geom_histogram(bins = 25, color = "white") +
geom_vline(xintercept = med_est, linewidth = 1.2) +
labs(title = "Estimated Median (Intercept-Only Quantile Regression)",
x = "y", y = "Frequency")

```

## 5.4 Estimated median with confidence interval (quantile regression)

```{r}
#get the estimated values from the linear prediction model
ap <- avg_predictions(mod_rq)

# save the as a tibble object for plotting
df_plot <- tibble(
  mean_est = ap$estimate[1],
  lcl = ap$conf.low[1],
  ucl = ap$conf.high[1]
)

# use ggplot to create a plot
ggplot(df_plot, aes(y = 1, x = mean_est)) +
  geom_point(size = 3) +
  geom_errorbar(aes(xmin = lcl, xmax = ucl), width = 0.1, linewidth = 1) + # add confidence interval 
  scale_y_continuous(breaks = NULL) + # remove the y-axis scale
  scale_x_continuous(limits = c(50, 90)) +   # # set x-axis range
  labs( # set labels 
    y = "",
    x = "Estimated Median (95% CI)"
  ) +
  theme_minimal()
```

# 6. Confidence Intervals and Standard Errors

Regression models estimate a population quantity. As in the prior course, we need a measure of uncertainty.

## 6.1 Linear regression

R directly computes model-based CIs (which you can also get using the `avg_predictions` function):

```{r}
confint(mod_lm)
```

For an intercept-only linear regression model, these confidence intervals are identical to the ones you would get from a one sample t-test

```{r}
t.test(df$lsas_post)
```

## 6.2 Quantile regression

Quantile regression standard errors rely on resampling:

```{r}
summary(mod_rq, se = "boot")
```

Bootstrap SEs are often more stable for quantiles.

## 6.3 Using marginaleffects for CIs

### Linear regression

```{r}
avg_predictions(mod_lm, conf_level = 0.95)
```

### Quantile regression

```{r}
avg_predictions(mod_rq, conf_level = 0.95)
```

These produce:

-   estimate

-   standard error

-   lower confidence limit

-   upper confidence limit

All computed consistently across model types.

# Summary

In this lab you learned:

-   how to fit **intercept-only regression models**

-   the difference between linear (mean) and quantile (median) regression

-   the structure of model objects

-   how to extract prediction-based estimates using `marginaleffects`

-   how to visualize model summaries with `ggplot`

-   how to compute confidence intervals and standard errors

This chapter forms the foundation for working with models that include predictors, which we will explore in the next session.
